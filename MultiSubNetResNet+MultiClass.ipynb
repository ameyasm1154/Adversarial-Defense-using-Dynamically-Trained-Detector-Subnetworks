{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MultiSubNetResNet+MultiClass.ipynb","provenance":[{"file_id":"10_BQ3XTVEc1tgZwnZjUz6B6Sc-e7Z-Wq","timestamp":1637801761765},{"file_id":"188cxWuwSZXX1z9EQoURDb31fk-HkMS70","timestamp":1637799083514}],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyOrncCI3sdgpntBA4sRgkH2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"9XE_EIidCkFC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637800875598,"user_tz":300,"elapsed":21372,"user":{"displayName":"Ameya Mahabaleshwarkar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWewArOnbcuIhn0zZGYi8CvzAMIgNfJVVvaTwTFg=s64","userId":"00795415078516995824"}},"outputId":"55a2db5d-4816-44ed-f106-3eaebbd101af"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"wjMguj11-COv"},"source":["import gc\n","import os\n","import sys\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import torchvision\n","from typing import overload, Union, Literal\n","\n","from PIL import Image\n","from torch.utils.data import DataLoader, Dataset\n","from torch.hub import load_state_dict_from_url\n","from torchvision import datasets, models, transforms\n","from torch.optim.lr_scheduler import ReduceLROnPlateau, ExponentialLR\n","from tqdm import tqdm\n","\n","from sklearn.metrics import accuracy_score\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.nn.init as init\n","\n","from torch.autograd import Variable"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YSNW4FaOb4Na"},"source":["N_ATTACKS = 3\n","N_SUBNET_LABELS = N_ATTACKS + 1 # add label for non-adversarial"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"F7TjhtIZ-HOh"},"source":["def _weights_init(m):\n","    classname = m.__class__.__name__\n","    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n","        init.kaiming_normal_(m.weight)\n","\n","class LambdaLayer(nn.Module):\n","    def __init__(self, lambd):\n","        super(LambdaLayer, self).__init__()\n","        self.lambd = lambd\n","\n","    def forward(self, x):\n","        return self.lambd(x)\n","\n","class BasicBlock(nn.Module):\n","    expansion = 1\n","\n","    def __init__(self, in_planes, planes, stride=1, option='A'):\n","        super(BasicBlock, self).__init__()\n","        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != planes:\n","            if option == 'A':\n","                \"\"\"\n","                For CIFAR10 ResNet paper uses option A.\n","                \"\"\"\n","                self.shortcut = LambdaLayer(lambda x:\n","                                            F.pad(x[:, :, ::2, ::2], (0, 0, 0, 0, planes//4, planes//4), \"constant\", 0))\n","            elif option == 'B':\n","                self.shortcut = nn.Sequential(\n","                     nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n","                     nn.BatchNorm2d(self.expansion * planes)\n","                )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.bn2(self.conv2(out))\n","        out += self.shortcut(x)\n","        out = F.relu(out)\n","        return out\n","\n","class ResNet(nn.Module):\n","    def __init__(self, block, num_blocks, num_classes=10):\n","        super(ResNet, self).__init__()\n","        self.in_planes = 16\n","\n","        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(16)\n","        self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1)\n","        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n","        self.layer3 = self._make_layer(block, 64, num_blocks[2], stride=2)\n","        self.linear = nn.Linear(64, num_classes)\n","\n","        self.apply(_weights_init)\n","\n","    def _make_layer(self, block, planes, num_blocks, stride):\n","        strides = [stride] + [1]*(num_blocks-1)\n","        layers = []\n","        for stride in strides:\n","            layers.append(block(self.in_planes, planes, stride))\n","            self.in_planes = planes * block.expansion\n","\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x, return_interm_layer=None):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.layer1(out)\n","        if return_interm_layer == 1:\n","            return out\n","        out = self.layer2(out)\n","        if return_interm_layer == 2:\n","            return out\n","        out = self.layer3(out)\n","        if return_interm_layer == 3:\n","            return out\n","        out = F.avg_pool2d(out, out.size()[3])\n","        out = out.view(out.size(0), -1)\n","        out = self.linear(out)\n","        \n","        return out\n","\n","\n","def resnet20():\n","    return ResNet(BasicBlock, [3, 3, 3])\n","\n","\n","def resnet32():\n","    return ResNet(BasicBlock, [5, 5, 5])\n","\n","\n","def resnet44():\n","    return ResNet(BasicBlock, [7, 7, 7])\n","\n","\n","def resnet56():\n","    return ResNet(BasicBlock, [9, 9, 9])\n","\n","\n","def resnet110():\n","    return ResNet(BasicBlock, [18, 18, 18])\n","\n","\n","def resnet1202():\n","    return ResNet(BasicBlock, [200, 200, 200])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BICuX46P-aZC"},"source":["class MultiClassSubNet(nn.Module):\n","    def __init__(self, in_channels):\n","        super(MultiClassSubNet, self).__init__()\n","        conv1 = nn.Conv2d(in_channels, 64, kernel_size=3, stride=2, padding=0, bias=False)\n","        bn1 = nn.BatchNorm2d(64)\n","        conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=0, bias=False)\n","        bn2 = nn.BatchNorm2d(128)\n","        conv3 = nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=0, bias=False)\n","        bn3 = nn.BatchNorm2d(256)\n","        relu = nn.ReLU(inplace=True)\n","        flatten = nn.Flatten()\n","        linear = nn.Linear(256, N_SUBNET_LABELS)\n","\n","        self.layers = nn.Sequential(\n","            conv1,\n","            bn1,\n","            relu,\n","            conv2,\n","            bn2,\n","            relu,\n","            conv3,\n","            bn3,\n","            relu,\n","            flatten,\n","            linear,\n","        )\n","\n","        self.layers.apply(self.init_param)\n","\n","    def forward(self, x, return_embedding=False):\n","        embedding = None\n","        for itr, layer in enumerate(self.layers):\n","          x = layer(x)\n","          if return_embedding and itr == len(self.layers)-1:\n","            embedding = x\n","\n","        return x, embedding\n","\n","    def init_param(self, param):\n","        if type(param) in [nn.Linear, nn.Conv2d]:\n","            nn.init.kaiming_uniform_(param.weight)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TGdnLXUVpmbY"},"source":["class MLP(nn.Module):\n","\n","    def __init__(self, size):\n","        super(MLP, self).__init__()\n","                \n","        self.model = nn.Sequential(\n","            nn.Linear(size[0], size[1]), \n","            nn.ReLU(),\n","            nn.Linear(size[1], size[2]), \n","            nn.ReLU(),\n","            nn.Linear(size[2], size[3]), \n","            nn.ReLU(),\n","        )\n","\n","    def forward(self, x):\n","        return self.model(x)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tgY0vnNbD6qh"},"source":["class End2EndSubNetsWithMLP(nn.Module):\n","\n","    def __init__(self, resnet, subnets: list, interm_layers: list, mlp):\n","        super(ToolChainClassifier, self).__init__()\n","\n","        self.subnets = subnets\n","        self.mlp = mlp\n","\n","    def forward(self, subnet_inputs):\n","        subnet_outputs = []\n","        for subnet_idx in range(len(self.subnets)):\n","          curr_subnet_output = self.subnets[subnet_idx](subnet_inputs[subnet_idx])\n","          subnet_outputs.append(curr_subnet_output)\n","\n","        mlp_input = torch.cat(subnet_outputs, axis=0)\n","        mlp_output = self.mlp(mlp_input)\n","\n","        return mlp_output"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dYxUfY3MAyeh"},"source":["### End-to-End Training"]},{"cell_type":"code","metadata":{"id":"9yLLEo-bA28v"},"source":["def train_multi_subnet_end2end(\n","    resnet_model,\n","    interm_layers: list,\n","    subnet_models: list,\n","    mlp_model=None,\n","    joint_optimizer=None,\n","    joint__criterion=None,\n","    joint_scheduler=None,\n","    unattacked_train_data=None,\n","    unattacked_test_data=None,\n","    attacked_train_data_list=None,\n","    attacked_test_data_list=None,\n","    device='cpu',\n","    epochs=100,\n","    batch_size=64,\n","    finetune=False,\n","):\n","    for subnet_model in subnet_models:\n","      subnet_model.train()\n","    resnet_model.eval()\n","    batches = []\n","\n","    for epoch in range(epochs):\n","\n","      avg_loss = 0.0\n","      for batch_itr in tqdm(range(0, len(unattacked_train_data), batch_size)):\n","          \n","          all_attacked_input, all_attacked_labels = [], []\n","          for label_id, attacked_train_data in enumerate(attacked_train_data_list):\n","            attacked_input = attacked_train_data[batch_itr:batch_itr+batch_size]\n","            all_attacked_input.extend(attacked_input)\n","\n","            attacked_labels = torch.ones((attacked_input.shape[0], label_id+1), dtype=torch.float32)\n","            all_attacked_labels.extend(attacked_labels)\n","\n","          all_attacked_input = torch.cat(all_attacked_input, axis=0)\n","          all_attacked_labels = torch.cat(all_attacked_labels, axis=0)\n","\n","          unattacked_input = unattacked_train_data[batch_itr:batch_itr+batch_size]\n","          unattacked_labels = torch.zeros((unattacked_input.shape[0], 1), dtype=torch.float32)\n","\n","          input = torch.cat((unattacked_input, all_attacked_input), axis=0)\n","          labels = torch.cat((unattacked_labels, all_attacked_labels), axis=0)\n","\n","          input, labels = input.to(device), labels.to(device)\n","\n","          for subnet_idx in range(len(subnet_models)):\n","            resnet_output = resnet_model(\n","                input.float(), return_interm_layer=interm_layers[subnet_idx]\n","            )\n","            subnet_output = subnet_models[subnet_idx](resnet_output)\n","\n","          input = resnet_model(input.float(), return_interm_layer=interm_layer)\n","          output = subnet_model(input)\n","\n","          loss = subnet_criterion(output, labels)\n","          loss.backward()\n","          avg_loss += loss.item()\n","\n","          subnet_optimizer.step()\n","\n","          del input\n","          del labels\n","          del loss\n","          torch.cuda.empty_cache()\n","\n","      val_loss, val_acc = test_multi_subnet_end2end(\n","          resnet_model,\n","          interm_layer,\n","          subnet_model,\n","          subnet_criterion,\n","          unattacked_test_data,\n","          attacked_test_data_list,\n","          device,\n","      )\n","\n","      print('Val Loss: {:.4f} | Val Accuracy: {:.4f}'.format(val_loss, val_acc))\n","      torch.save({\n","          'epoch': epoch,\n","          'model_state_dict': resnet_model.state_dict(),\n","          'optimizer_state_dict': subnet_optimizer.state_dict(),\n","      }, './' + str(epoch) + 'model.pt')\n","\n","      # subnet_scheduler.step(val_loss)\n","\n","def test_multi_subnet_end2end(\n","    resnet_model,\n","    interm_layers: list,\n","    subnet_models: list,\n","    subnet_criterions: list,\n","    mlp_model=None,\n","    mlp_criterion=None,\n","    unattacked_test_data=None,\n","    attacked_test_data_list=None,\n","    device='cpu',\n","    batch_size=64,\n","    test_mode: Literal[\"majority_vote\", \"mlp\"] = \"mlp\",\n","):\n","    resnet_model.eval()\n","    subnet_model.eval()\n","    test_loss = []\n","    accuracies = []\n","\n","    for batch_itr in tqdm(range(0, len(unattacked_test_data), batch_size)):\n","        all_attacked_input, all_attacked_labels = [], []\n","        for label_id, attacked_test_data in enumerate(attacked_test_data_list):\n","          attacked_input = attacked_test_data[batch_itr:batch_itr+batch_size]\n","          all_attacked_input.extend(attacked_input)\n","\n","          attacked_labels = torch.ones((attacked_input.shape[0], label_id+1), dtype=torch.float32)\n","          all_attacked_labels.extend(attacked_labels)\n","\n","        all_attacked_input = torch.cat(all_attacked_input, axis=0)\n","        all_attacked_labels = torch.cat(all_attacked_labels, axis=0)\n","\n","        unattacked_input = unattacked_test_data[batch_itr:batch_itr+batch_size]\n","        unattacked_labels = torch.zeros((unattacked_input.shape[0], 1), dtype=torch.float32)\n","\n","        input = torch.cat((unattacked_input, all_attacked_input), axis=0)\n","        labels = torch.cat((unattacked_labels, all_attacked_labels), axis=0)\n","\n","        input, labels = input.to(device), labels.to(device)\n","\n","        with torch.no_grad():\n","            input = resnet_model(input.float(), return_interm_layer=interm_layer)\n","            output = subnet_model(input)\n","\n","        pred_labels = torch.argmax(output).float()\n","        loss = criterion(output, labels)\n","\n","        accuracy = accuracy_score(pred_labels.flatten().cpu(), labels.flatten().cpu())\n","        accuracies.append(accuracy)\n","        test_loss.extend([loss.item()]*input.size()[0])\n","        \n","        del input\n","        del labels\n","        del loss\n","        torch.cuda.empty_cache()\n","\n","    subnet_model.train()\n","\n","    return np.mean(test_loss), np.mean(accuracies)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uKtmkt3bA3Qb"},"source":["### Individual Training"]},{"cell_type":"code","metadata":{"id":"7ORHQWo-A6KQ"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fjqA1KiJ-hLC"},"source":["def train_subnet(\n","    resnet_model,\n","    interm_layer,\n","    subnet_model,\n","    subnet_optimizer,\n","    subnet_criterion,\n","    subnet_scheduler,\n","    unattacked_train_data,\n","    unattacked_test_data,\n","    attacked_train_data_list,\n","    attacked_test_data_list,\n","    device,\n","    epochs=100,\n","    batch_size=64,\n","):\n","    subnet_model.train()\n","    resnet_model.eval()\n","    batches = []\n","\n","    for epoch in range(epochs):\n","\n","      avg_loss = 0.0\n","      for batch_itr in tqdm(range(0, len(unattacked_train_data), batch_size)):\n","          \n","          all_attacked_input, all_attacked_labels = [], []\n","          for label_id, attacked_train_data in enumerate(attacked_train_data_list):\n","            attacked_input = attacked_train_data[batch_itr:batch_itr+batch_size]\n","            all_attacked_input.extend(attacked_input)\n","\n","            attacked_labels = torch.ones((attacked_input.shape[0], label_id+1), dtype=torch.float32)\n","            all_attacked_labels.extend(attacked_labels)\n","\n","          all_attacked_input = torch.cat(all_attacked_input, axis=0)\n","          all_attacked_labels = torch.cat(all_attacked_labels, axis=0)\n","\n","          unattacked_input = unattacked_train_data[batch_itr:batch_itr+batch_size]\n","          unattacked_labels = torch.zeros((unattacked_input.shape[0], 1), dtype=torch.float32)\n","\n","          input = torch.cat((unattacked_input, all_attacked_input), axis=0)\n","          labels = torch.cat((unattacked_labels, all_attacked_labels), axis=0)\n","\n","          input, labels = input.to(device), labels.to(device)\n","\n","          input = resnet_model(input.float(), return_interm_layer=interm_layer)\n","          output = subnet_model(input)\n","\n","          loss = subnet_criterion(output, labels)\n","          loss.backward()\n","          avg_loss += loss.item()\n","\n","          subnet_optimizer.step()\n","\n","          del input\n","          del labels\n","          del loss\n","          torch.cuda.empty_cache()\n","\n","      val_loss, val_acc = test_subnet(\n","          resnet_model,\n","          interm_layer,\n","          subnet_model,\n","          subnet_criterion,\n","          unattacked_test_data,\n","          attacked_test_data_list,\n","          device,\n","      )\n","\n","      print('Val Loss: {:.4f} | Val Accuracy: {:.4f}'.format(val_loss, val_acc))\n","      torch.save({\n","          'epoch': epoch,\n","          'model_state_dict': resnet_model.state_dict(),\n","          'optimizer_state_dict': subnet_optimizer.state_dict(),\n","      }, './' + str(epoch) + 'model.pt')\n","\n","      # subnet_scheduler.step(val_loss)\n","\n","def test_subnet(\n","    resnet_model,\n","    interm_layer,\n","    subnet_model,\n","    criterion,\n","    unattacked_test_data,\n","    attacked_test_data_list,\n","    device,\n","    batch_size=64,\n","):\n","    resnet_model.eval()\n","    subnet_model.eval()\n","    test_loss = []\n","    accuracies = []\n","\n","    for batch_itr in tqdm(range(0, len(unattacked_test_data), batch_size)):\n","        all_attacked_input, all_attacked_labels = [], []\n","        for label_id, attacked_test_data in enumerate(attacked_test_data_list):\n","          attacked_input = attacked_test_data[batch_itr:batch_itr+batch_size]\n","          all_attacked_input.extend(attacked_input)\n","\n","          attacked_labels = torch.ones((attacked_input.shape[0], label_id+1), dtype=torch.float32)\n","          all_attacked_labels.extend(attacked_labels)\n","\n","        all_attacked_input = torch.cat(all_attacked_input, axis=0)\n","        all_attacked_labels = torch.cat(all_attacked_labels, axis=0)\n","\n","        unattacked_input = unattacked_test_data[batch_itr:batch_itr+batch_size]\n","        unattacked_labels = torch.zeros((unattacked_input.shape[0], 1), dtype=torch.float32)\n","\n","        input = torch.cat((unattacked_input, all_attacked_input), axis=0)\n","        labels = torch.cat((unattacked_labels, all_attacked_labels), axis=0)\n","\n","        input, labels = input.to(device), labels.to(device)\n","\n","        with torch.no_grad():\n","            input = resnet_model(input.float(), return_interm_layer=interm_layer)\n","            output = subnet_model(input)\n","\n","        pred_labels = torch.argmax(output).float()\n","        loss = criterion(output, labels)\n","\n","        accuracy = accuracy_score(pred_labels.flatten().cpu(), labels.flatten().cpu())\n","        accuracies.append(accuracy)\n","        test_loss.extend([loss.item()]*input.size()[0])\n","        \n","        del input\n","        del labels\n","        del loss\n","        torch.cuda.empty_cache()\n","\n","    subnet_model.train()\n","\n","    return np.mean(test_loss), np.mean(accuracies)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KSleqNm_w5CA"},"source":["def Normalize0to1(AA):\n","    AA[:, :, :, 0] -= AA[:, :, :, 0].min().item()\n","    AA[:, :, :, 0] /= AA[:, :, :, 0].max().item()\n","\n","    AA[:, :, :, 1] -= AA[:, :, :, 1].min().item()\n","    AA[:, :, :, 1] /= AA[:, :, :, 1].max().item()\n","\n","    AA[:, :, :, 2] -= AA[:, :, :, 2].min().item()\n","    AA[:, :, :, 2] /= AA[:, :, :, 2].max().item()\n","\n","    return AA / 225."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XMnBGC9TGQFI"},"source":["batch_size = 64\n","\n","normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","\n","unattacked_data_path = \"/content/drive/MyDrive/11785/Project/unattack_test.npy\"\n","unattacked_data = np.load(unattacked_data_path, allow_pickle=True).astype(float)\n","unattacked_data = torch.from_numpy(unattacked_data.transpose(0, 3, 1, 2))\n","unattacked_data = Normalize0to1(unattacked_data)\n","unattacked_data = normalize(unattacked_data)\n","unattacked_train_data = unattacked_data[:9000]\n","unattacked_test_data = unattacked_data[9000:]\n","\n","attacked_data_path = \"/content/drive/MyDrive/11785/Project/attack_new.npy\"\n","attacked_data = np.load(attacked_data_path, allow_pickle=True).astype(float)\n","attacked_data = torch.from_numpy(attacked_data.transpose(0, 3, 1, 2))\n","attacked_data = Normalize0to1(attacked_data)\n","attacked_data = normalize(attacked_data)\n","attacked_train_data = attacked_data[:9000]\n","attacked_test_data = attacked_data[9000:]\n","\n","# TODO: hack for testing, change to list of actual attacks\n","attacked_train_data_list = [attacked_train_data] * 3\n","attacked_test_data_list = [attacked_test_data] * 3"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mRiNlZue-kxG"},"source":["cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if cuda else \"cpu\")\n","\n","resnet_model = resnet32()\n","resnet_model.to(device)\n","checkpoint = torch.load(\"/content/drive/MyDrive/11785/Project/resnet32.th\")\n","mod_checkpoint = {k.replace(\"module.\", \"\"): v for k, v in checkpoint['state_dict'].items()}\n","resnet_model.load_state_dict(mod_checkpoint)\n","resnet_optimizer = torch.optim.SGD(resnet_model.parameters(), lr=0.1, weight_decay=5e-5, momentum=0.9)\n","resnet_criterion = nn.CrossEntropyLoss()\n","resnet_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(resnet_optimizer, T_0=10, T_mult=2, eta_min=0.01, last_epoch=-1)\n","\n","# output size at diff intermediate layers of resnet\n","interm_layer2dim = {1: 16, 2: 32, 3: 64}\n","interm_layer = 2\n","\n","subnet_model = MultiClassSubNet(interm_layer2dim[interm_layer])\n","subnet_model.to(device)\n","subnet_optimizer = torch.optim.Adam(subnet_model.parameters(), lr=0.0001, betas=(0.99, 0.999))\n","subnet_criterion = nn.CrossEntropyLoss()\n","subnet_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(subnet_optimizer, T_0=10, T_mult=2, eta_min=0.01, last_epoch=-1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1Iq2wgAR-2Oj"},"source":["train_subnet(\n","  resnet_model,\n","  interm_layer,\n","  subnet_model,\n","  subnet_optimizer,\n","  subnet_criterion,\n","  subnet_scheduler,\n","  unattacked_train_data,\n","  unattacked_test_data,\n","  attacked_train_data_list,\n","  attacked_test_data_list,\n","  device,\n","  epochs=50,\n",")"],"execution_count":null,"outputs":[]}]}