{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Combined PGD SubNetworkDynamicTraining.ipynb","provenance":[{"file_id":"1R7dVbv4s3MSVnBDPF8OezBqt0_ZQFSQi","timestamp":1638232909614}],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyP71TkU+W3l4tHlUo2kwdqW"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"45c8566feef64d5d8bae97d8e6aeeaf7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a0c61a5da8c64859a6cc45b5258d4496","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_3133bd70f1db4e11bd4b1a9f21d6f952","IPY_MODEL_6b06af96543b4d748bf3c42eb600f2f1","IPY_MODEL_c5bbeb069c764dc9a7d546b137b77010"]}},"a0c61a5da8c64859a6cc45b5258d4496":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3133bd70f1db4e11bd4b1a9f21d6f952":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_955197ae153649d6896dd6c2a4b5793f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_90136e23b0834ccf9d1c930c6885cd71"}},"6b06af96543b4d748bf3c42eb600f2f1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_e5e1a7d5067b43a39516312907cbc8d9","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":141,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":141,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9bcdce1956dc41bea05f795ee7c3f4b9"}},"c5bbeb069c764dc9a7d546b137b77010":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ef94712fb7bf46e991d5c24a38275002","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 141/141 [00:22&lt;00:00,  6.30it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3bd9d8cbf34241ea90b542ef70b18c80"}},"955197ae153649d6896dd6c2a4b5793f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"90136e23b0834ccf9d1c930c6885cd71":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e5e1a7d5067b43a39516312907cbc8d9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"9bcdce1956dc41bea05f795ee7c3f4b9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ef94712fb7bf46e991d5c24a38275002":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3bd9d8cbf34241ea90b542ef70b18c80":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"077035c79e6f4c088ce3080ccd924a43":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_4dbfcb77ecb24d1bbfc50cc879c0fb4c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_166fe3c004bd40cd8d6cc1244ca1d5ec","IPY_MODEL_5444ccf1f3e6427cbad50acf5c88879c","IPY_MODEL_b603387bd50f47e3943958085f3e2fc4"]}},"4dbfcb77ecb24d1bbfc50cc879c0fb4c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"166fe3c004bd40cd8d6cc1244ca1d5ec":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_60bf0bf14c664283b7c6736f4e64ede2","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_db8a9f06d34b45be8112c1596b9a1f0b"}},"5444ccf1f3e6427cbad50acf5c88879c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_9580d6851d39420bac15fe04a74e3478","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":16,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":16,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6d33132eb71e4b0abca6509326881138"}},"b603387bd50f47e3943958085f3e2fc4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_5c7b6598b67049c19cdebdc21226e39a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 16/16 [00:02&lt;00:00,  7.13it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a474febabd034853b862b28413533180"}},"60bf0bf14c664283b7c6736f4e64ede2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"db8a9f06d34b45be8112c1596b9a1f0b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9580d6851d39420bac15fe04a74e3478":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"6d33132eb71e4b0abca6509326881138":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5c7b6598b67049c19cdebdc21226e39a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a474febabd034853b862b28413533180":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"71fcddd87ab44b0fb68cc188c34fa990":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_8055326fc1b74d5b88f7d5a8f81d8aab","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_80b3c9d053994bfb84181fa188583ea5","IPY_MODEL_f9679077cf434ea1b0a54aa470008ace","IPY_MODEL_468fa5e692d546d1ab276f0edb2a1233"]}},"8055326fc1b74d5b88f7d5a8f81d8aab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"80b3c9d053994bfb84181fa188583ea5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_355e40f871e9413888d1bfc6b2955272","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7ce6477765ff4c31a9688121a74d4911"}},"f9679077cf434ea1b0a54aa470008ace":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_f253670703024f2a92c6638e2ec2464f","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":141,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":141,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6c650b0b4dc043278c8e47c34ad242a7"}},"468fa5e692d546d1ab276f0edb2a1233":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2add25ed869e432491c61a9c2136171e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 141/141 [00:22&lt;00:00,  6.43it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e303c681f6ba432983eb69adb062038a"}},"355e40f871e9413888d1bfc6b2955272":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7ce6477765ff4c31a9688121a74d4911":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f253670703024f2a92c6638e2ec2464f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"6c650b0b4dc043278c8e47c34ad242a7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2add25ed869e432491c61a9c2136171e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e303c681f6ba432983eb69adb062038a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b9a4b0ba3cec40769680e93e4e81624b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_b69042a0c34a4d029392de61b9757867","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_a3b3b06fcfb347b39454475c4265a21b","IPY_MODEL_976983f0c4564b538ec4e085b06c1246","IPY_MODEL_68c3c3c5e2ba457290fb878205e0b11d"]}},"b69042a0c34a4d029392de61b9757867":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a3b3b06fcfb347b39454475c4265a21b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7ea40c89da234b4386be0c6286d5060c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_23612e281c754a1eb385be56b38b59cc"}},"976983f0c4564b538ec4e085b06c1246":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_626c7ae78525420c99670394f5d075f6","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":16,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":16,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_347400c9ae04423ea33d86d98d84d884"}},"68c3c3c5e2ba457290fb878205e0b11d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_202a517ea2bc42c284d259a7e9788a29","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 16/16 [00:02&lt;00:00,  7.37it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a7142eaee32e4b7397ca4dd04736a5a3"}},"7ea40c89da234b4386be0c6286d5060c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"23612e281c754a1eb385be56b38b59cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"626c7ae78525420c99670394f5d075f6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"347400c9ae04423ea33d86d98d84d884":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"202a517ea2bc42c284d259a7e9788a29":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a7142eaee32e4b7397ca4dd04736a5a3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0d27b0baf68745c5afab331d0b522745":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_927e1ff9f71548fdaa45f48d196bb04e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_35aafb90d3424079b453ef83a5d2df0b","IPY_MODEL_5bed852efc704e378a8eec4a91c2ec35","IPY_MODEL_2b7cff8ca75b4a529af0d561b74eedfc"]}},"927e1ff9f71548fdaa45f48d196bb04e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"35aafb90d3424079b453ef83a5d2df0b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_617c86fede034d0ab6bb13b315afd8ad","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4ade0433e5ef4fdbba6cae00b2bc5ca7"}},"5bed852efc704e378a8eec4a91c2ec35":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_72d84ae7a6aa455c979a039c393ed6b7","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":141,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":141,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a2e2b27749db478f8d756404e79e155f"}},"2b7cff8ca75b4a529af0d561b74eedfc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b252fae49bc748abbea71ee5eed2f968","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 141/141 [00:22&lt;00:00,  6.50it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2e0358c4418c4ed4b23d5b103156b44c"}},"617c86fede034d0ab6bb13b315afd8ad":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4ade0433e5ef4fdbba6cae00b2bc5ca7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"72d84ae7a6aa455c979a039c393ed6b7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a2e2b27749db478f8d756404e79e155f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b252fae49bc748abbea71ee5eed2f968":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2e0358c4418c4ed4b23d5b103156b44c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fec1c006dc5941d39520035e46f9c91b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_d0ce4f5ede9c4bed86021537d75ed81d","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_8ab54aefe8f645af949c952d73be716e","IPY_MODEL_262a1df2157f463abe0ba686d6efee1c","IPY_MODEL_7e4e4b49922745ba9a5126147339e34d"]}},"d0ce4f5ede9c4bed86021537d75ed81d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8ab54aefe8f645af949c952d73be716e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b1bae2dd3c28490cab92670a44c9324e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a29c3ac6510a433983eb7fbb0bfe8489"}},"262a1df2157f463abe0ba686d6efee1c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_38877e1c51a142ba84735582b93ce40a","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":16,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":16,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9d14497226954b15a8c074c5747b3e29"}},"7e4e4b49922745ba9a5126147339e34d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_564f1c197f62469c836be509990308ab","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 16/16 [00:02&lt;00:00,  7.18it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_658d27a4cfc34ea49aee8045ef8ce3a3"}},"b1bae2dd3c28490cab92670a44c9324e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a29c3ac6510a433983eb7fbb0bfe8489":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"38877e1c51a142ba84735582b93ce40a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"9d14497226954b15a8c074c5747b3e29":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"564f1c197f62469c836be509990308ab":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"658d27a4cfc34ea49aee8045ef8ce3a3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"50b492ea29574976939eded9fa077b45":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_5066aa757ffd425e95e5d46c49716674","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_58ae97416c3d4a20bef849538872f08b","IPY_MODEL_b8295289c9b8433aafb050ad57193ea1","IPY_MODEL_1f29083b692c4faa91a3d8e1a5e5bae8"]}},"5066aa757ffd425e95e5d46c49716674":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"58ae97416c3d4a20bef849538872f08b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_01f00600d33d457a86fe5ab7988daddb","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f787a63920ea4175a1f7ae2312851bc5"}},"b8295289c9b8433aafb050ad57193ea1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_90eaaf2216334c5fbca178bdf021b73d","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":141,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":141,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c9a5ed36fdee4923bec98f5d228e64ab"}},"1f29083b692c4faa91a3d8e1a5e5bae8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_371df42248bc4109845e9265c6385d2f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 141/141 [00:22&lt;00:00,  6.45it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_16019ab234dc4dc09beae1076baa6c74"}},"01f00600d33d457a86fe5ab7988daddb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f787a63920ea4175a1f7ae2312851bc5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"90eaaf2216334c5fbca178bdf021b73d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"c9a5ed36fdee4923bec98f5d228e64ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"371df42248bc4109845e9265c6385d2f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"16019ab234dc4dc09beae1076baa6c74":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f50ace8573c54d3da27c641e93ce8928":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_1d18eaf3eee746518242983d5f5cfd58","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_27db5ceef9c8482fbf76984fdb57af34","IPY_MODEL_f7d406910994469bba32d19324754392","IPY_MODEL_e28246f458ee487eb4211444e4278505"]}},"1d18eaf3eee746518242983d5f5cfd58":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"27db5ceef9c8482fbf76984fdb57af34":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_1d56d1f9acd7480092c5c5f1f9ece54c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_cfcb275b83314e849c7ce0e6c562d8a0"}},"f7d406910994469bba32d19324754392":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d20dc351c2b44b599b49ad2f1ba86cc1","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":16,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":16,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a5d995942029462fb5284eb4ddbcc80f"}},"e28246f458ee487eb4211444e4278505":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_bdf409402fc24c8cbf92a426a5695368","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 16/16 [00:02&lt;00:00,  7.21it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_440cdeaaafd440178ae153995fe03061"}},"1d56d1f9acd7480092c5c5f1f9ece54c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"cfcb275b83314e849c7ce0e6c562d8a0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d20dc351c2b44b599b49ad2f1ba86cc1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a5d995942029462fb5284eb4ddbcc80f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bdf409402fc24c8cbf92a426a5695368":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"440cdeaaafd440178ae153995fe03061":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"928d89ecbd9e483bbdb6c67e4d00e60a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_56c3ee3f29b24dcabe7712748bfeaba7","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f6ab69c0f6e542ba8390eb23e371f680","IPY_MODEL_84492d2e06fc479794fd6c6211c5a796","IPY_MODEL_5d52d802719c40d5b4a2944c774f66b5"]}},"56c3ee3f29b24dcabe7712748bfeaba7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f6ab69c0f6e542ba8390eb23e371f680":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_1b4bebd5a1c546eab758f904eda1395a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0bc90379304f4ed5a6d750bfbbac607d"}},"84492d2e06fc479794fd6c6211c5a796":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_94f897019fce4028965701e513d49fd2","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":141,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":141,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_aabc47efdedb431dad82bef35da37827"}},"5d52d802719c40d5b4a2944c774f66b5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_33199ff45aa34cf39bd7c67bf9b55e58","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 141/141 [00:22&lt;00:00,  6.50it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fc2910224daa49429167fc6bf42d8b52"}},"1b4bebd5a1c546eab758f904eda1395a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"0bc90379304f4ed5a6d750bfbbac607d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"94f897019fce4028965701e513d49fd2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"aabc47efdedb431dad82bef35da37827":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"33199ff45aa34cf39bd7c67bf9b55e58":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"fc2910224daa49429167fc6bf42d8b52":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fb987c7fe98e41939086fd2fa4d42376":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_e693b5d83162416a9ccfde153eb07290","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_770a5df2e80b4f1ca38ae86bde46e2c8","IPY_MODEL_7f3b6f585d4645219a11244753e83684","IPY_MODEL_56e48d92117a4b8faaa7bc3682ca2c8e"]}},"e693b5d83162416a9ccfde153eb07290":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"770a5df2e80b4f1ca38ae86bde46e2c8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_04675d3794bc4910a3a079de3f76d08d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_855d99d9017d4dba951c5ee892910bec"}},"7f3b6f585d4645219a11244753e83684":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_a657a4a421704c3bb615648e2d2b425d","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":16,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":16,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_00682514031d469baf77bfb08d3c6e6a"}},"56e48d92117a4b8faaa7bc3682ca2c8e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f8990627b19b4a64b978b7aa32a37225","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 16/16 [00:02&lt;00:00,  7.11it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2392e6347b8f44af97a2968579501d89"}},"04675d3794bc4910a3a079de3f76d08d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"855d99d9017d4dba951c5ee892910bec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a657a4a421704c3bb615648e2d2b425d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"00682514031d469baf77bfb08d3c6e6a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f8990627b19b4a64b978b7aa32a37225":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2392e6347b8f44af97a2968579501d89":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"Fw18xK0ANwvs"},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OAIckN--awoV"},"source":["! pip install torchattacks\n","! pip install adversarial-robustness-toolbox==1.8.1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YrSp_qMjQzTI","executionInfo":{"status":"ok","timestamp":1638555159308,"user_tz":300,"elapsed":6349,"user":{"displayName":"Ameya Mahabaleshwarkar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWewArOnbcuIhn0zZGYi8CvzAMIgNfJVVvaTwTFg=s64","userId":"00795415078516995824"}}},"source":["import gc\n","import os\n","import sys\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import torchattacks\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.nn.init as init\n","import torch.optim as optim\n","import torchvision\n","from torch.utils.data import DataLoader, Dataset\n","from torch.hub import load_state_dict_from_url\n","from torchvision import datasets, models, transforms\n","from torch.optim.lr_scheduler import ReduceLROnPlateau, ExponentialLR\n","from torch.autograd import Variable\n","\n","from PIL import Image\n","from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n","from tqdm.notebook import tqdm"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"2XiVxTXV1njm","executionInfo":{"status":"ok","timestamp":1638555159309,"user_tz":300,"elapsed":6,"user":{"displayName":"Ameya Mahabaleshwarkar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWewArOnbcuIhn0zZGYi8CvzAMIgNfJVVvaTwTFg=s64","userId":"00795415078516995824"}}},"source":["PGD_ATTACK_EPS = 2/255"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bp4VA6sERZg3"},"source":["### Base Classifier - ResNet"]},{"cell_type":"code","metadata":{"id":"ssh9qP_dQ1yW","executionInfo":{"status":"ok","timestamp":1638558139129,"user_tz":300,"elapsed":230,"user":{"displayName":"Ameya Mahabaleshwarkar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWewArOnbcuIhn0zZGYi8CvzAMIgNfJVVvaTwTFg=s64","userId":"00795415078516995824"}}},"source":["def _weights_init(m):\n","    classname = m.__class__.__name__\n","    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n","        init.kaiming_normal_(m.weight)\n","\n","class LambdaLayer(nn.Module):\n","    def __init__(self, lambd):\n","      super(LambdaLayer, self).__init__()\n","      self.lambd = lambd\n","\n","    def forward(self, x):\n","      return self.lambd(x)\n","\n","class BasicBlock(nn.Module):\n","    expansion = 1\n","\n","    def __init__(self, in_planes, planes, stride=1, option='A'):\n","        super(BasicBlock, self).__init__()\n","        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != planes:\n","            if option == 'A':\n","                \"\"\"\n","                For CIFAR10 ResNet paper uses option A.\n","                \"\"\"\n","                self.shortcut = LambdaLayer(lambda x:\n","                                            F.pad(x[:, :, ::2, ::2], (0, 0, 0, 0, planes//4, planes//4), \"constant\", 0))\n","            elif option == 'B':\n","                self.shortcut = nn.Sequential(\n","                     nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n","                     nn.BatchNorm2d(self.expansion * planes)\n","                )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.bn2(self.conv2(out))\n","        out += self.shortcut(x)\n","        out = F.relu(out)\n","        return out\n","\n","\n","class ResNet(nn.Module):\n","    def __init__(self, block, num_blocks, num_classes=10):\n","        super(ResNet, self).__init__()\n","        self.in_planes = 16\n","\n","        self.in_channels = 1 # 3 for CIFAR OR 1 for MNIST\n","        self.conv1 = nn.Conv2d(self.in_channels, 16, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(16)\n","        self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1)\n","        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n","        self.layer3 = self._make_layer(block, 64, num_blocks[2], stride=2)\n","        self.linear = nn.Linear(64, num_classes)\n","\n","        self.apply(self._weights_init)\n","\n","    def _weights_init(self, m):\n","        classname = m.__class__.__name__\n","        if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n","          nn.init.kaiming_normal_(m.weight)\n","    \n","    def _make_layer(self, block, planes, num_blocks, stride):\n","        strides = [stride] + [1]*(num_blocks-1)\n","        layers = []\n","        for stride in strides:\n","            layers.append(block(self.in_planes, planes, stride))\n","            self.in_planes = planes * block.expansion\n","\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x, return_interm_layer=None):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.layer1(out)\n","        if return_interm_layer == 1:\n","            return out\n","        out = self.layer2(out)\n","        if return_interm_layer == 2:\n","            return out\n","        out = self.layer3(out)\n","        if return_interm_layer == 3:\n","            return out\n","        out = F.avg_pool2d(out, out.size()[3])\n","        out = out.view(out.size(0), -1)\n","        if return_interm_layer == -1:\n","            return out\n","        out = self.linear(out)\n","        \n","        return out\n","\n","def resnet20():\n","    return ResNet(BasicBlock, [3, 3, 3])\n","\n","def resnet32():\n","    return ResNet(BasicBlock, [5, 5, 5])\n","\n","def resnet44():\n","    return ResNet(BasicBlock, [7, 7, 7])\n","\n","def resnet56():\n","    return ResNet(BasicBlock, [9, 9, 9])\n","\n","def resnet110():\n","    return ResNet(BasicBlock, [18, 18, 18])\n","\n","def resnet1202():\n","    return ResNet(BasicBlock, [200, 200, 200])"],"execution_count":194,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t5M0vERxRd-N"},"source":["### SubNetwork"]},{"cell_type":"code","metadata":{"id":"E5jNIVmYRdfQ","executionInfo":{"status":"ok","timestamp":1638558139317,"user_tz":300,"elapsed":2,"user":{"displayName":"Ameya Mahabaleshwarkar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWewArOnbcuIhn0zZGYi8CvzAMIgNfJVVvaTwTFg=s64","userId":"00795415078516995824"}}},"source":["class SubNet(nn.Module):\n","    def __init__(self, in_channels):\n","        super(SubNet, self).__init__()\n","        conv1 = nn.Conv2d(in_channels, 96, kernel_size=3, stride=1, padding=0, bias=False)\n","        bn1 = nn.BatchNorm2d(96)\n","        conv2 = nn.Conv2d(96, 192, kernel_size=3, stride=1, padding=0, bias=False)\n","        bn2 = nn.BatchNorm2d(192)\n","        conv3 = nn.Conv2d(192, 192, kernel_size=3, stride=1, padding=0, bias=False)\n","        bn3 = nn.BatchNorm2d(192)\n","        conv4 = nn.Conv2d(192, 2, kernel_size=1, stride=1, padding=0, bias=False)\n","        bn4 = nn.BatchNorm2d(2)\n","        relu = nn.ReLU(inplace=True)\n","        avgpool = nn.AdaptiveAvgPool2d((1, 1))\n","        flatten = nn.Flatten()\n","        linear = nn.Linear(2, 1)\n","        sigmoid = nn.Sigmoid()\n","\n","        self.layers = nn.Sequential(\n","            conv1,\n","            bn1,\n","            relu,\n","            conv2,\n","            bn2,\n","            relu,\n","            conv3,\n","            bn3,\n","            conv4,\n","            bn4,\n","            relu,\n","            avgpool,\n","            flatten,\n","            linear,\n","            sigmoid,\n","        )\n","\n","        self.layers.apply(self.init_param)\n","\n","    def forward(self, x):\n","        for itr, layer in enumerate(self.layers):\n","          x = layer(x)\n","\n","        return x\n","\n","    def init_param(self, param):\n","        if type(param) in [nn.Linear, nn.Conv2d]:\n","            nn.init.kaiming_uniform_(param.weight)"],"execution_count":195,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B4YTvSH8XthX"},"source":["### Train and Test Loops"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KXTjaUt6fdal","executionInfo":{"status":"ok","timestamp":1638558140159,"user_tz":300,"elapsed":9,"user":{"displayName":"Ameya Mahabaleshwarkar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWewArOnbcuIhn0zZGYi8CvzAMIgNfJVVvaTwTFg=s64","userId":"00795415078516995824"}},"outputId":"ed39d21c-5de6-4c48-881f-8d037e835129"},"source":["!ls '/content/drive/MyDrive/11785 - Project/data'"],"execution_count":196,"outputs":[{"output_type":"stream","name":"stdout","text":["benign_cifar.npy\t      fgsm_mnist_eps0.5.npy\n","benign_cifar_train.npy\t      pgd_cifar_default_art.npy\n","benign_mnist.npy\t      pgd_cifar_default_torchattacks_new.npy\n","benign_mnist_train.npy\t      pgd_cifar_eps0.1_torchattacks.npy\n","cwlinf_cifar_default_art.npy  pgd_cifar_eps0.3_alpha0.1_steps7.npy\n","cwlinf_default_art.npy\t      pgd_mnist_default_art.npy\n","cwlinf_mnist_default_art.npy  pgd_mnist_eps0.3_alpha0.1_steps7.npy\n","fgsm_cifar_default_art.npy\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jxcB_Ay5fazc","executionInfo":{"status":"ok","timestamp":1638558140368,"user_tz":300,"elapsed":5,"user":{"displayName":"Ameya Mahabaleshwarkar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWewArOnbcuIhn0zZGYi8CvzAMIgNfJVVvaTwTFg=s64","userId":"00795415078516995824"}},"outputId":"e98e7332-ba66-40d3-ba30-93e81f2e61b1"},"source":["batch_size = 64\n","\n","normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","\n","unattacked_data_path = \"/content/drive/MyDrive/11785 - Project/data/benign_mnist.npy\"\n","unattacked_data = np.load(unattacked_data_path, allow_pickle=True).astype(float)\n","\n","# unattacked_data = torch.from_numpy(unattacked_data.transpose(0, 3, 1, 2))\n","unattacked_data = torch.from_numpy(unattacked_data)\n","print(f\"unattacked data shape: {unattacked_data.shape}\")\n","\n","# # pre-processing\n","# unattacked_data = Normalize0to1(unattacked_data)\n","# unattacked_data = normalize(unattacked_data)\n","\n","# train-test split\n","unattacked_train_data = unattacked_data[:9000]\n","unattacked_test_data = unattacked_data[9000:]\n","\n","\n","\n","attacked_data_path = \"/content/drive/MyDrive/11785 - Project/data/cwlinf_mnist_default_art.npy\"\n","# attacked_data_path = \"/content/drive/MyDrive/11785 - Project/data/cwlinf_cifar_default_art.npy\"\n","# attacked_data_path = \"/content/drive/MyDrive/11785 - Project/data/fgsm_cifar_default_art.npy\"\n","# attacked_data_path = \"/content/drive/MyDrive/11785 - Project/data/pgd_cifar_default_torchattacks_new.npy\"\n","attacked_data = np.load(attacked_data_path, allow_pickle=True).astype(float)\n","# attacked_data = torch.from_numpy(attacked_data.transpose(1, 0, 2, 3))\n","attacked_data = torch.from_numpy(attacked_data)\n","print(f\"attacked data shape: {attacked_data.shape}\")\n","\n","# # pre-processing\n","# attacked_data = Normalize0to1(attacked_data)\n","# attacked_data = normalize(attacked_data)\n","\n","# train-test split\n","attacked_train_data = attacked_data[:9000]\n","attacked_test_data = attacked_data[9000:]"],"execution_count":197,"outputs":[{"output_type":"stream","name":"stdout","text":["unattacked data shape: torch.Size([10000, 1, 28, 28])\n","attacked data shape: torch.Size([10000, 1, 28, 28])\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pNfPvmRpjiHE","executionInfo":{"status":"ok","timestamp":1638558140687,"user_tz":300,"elapsed":187,"user":{"displayName":"Ameya Mahabaleshwarkar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWewArOnbcuIhn0zZGYi8CvzAMIgNfJVVvaTwTFg=s64","userId":"00795415078516995824"}},"outputId":"41a56e90-a051-4a8c-83e3-77c0c76d0b49"},"source":["!ls '/content/drive/MyDrive/11785 - Project/'"],"execution_count":198,"outputs":[{"output_type":"stream","name":"stdout","text":["AdversarialDetection.pdf  imgs\n","cifar10_model.pth\t  mnist_model.pth\n","data\t\t\t  mnist-resnet-dynamic-adv-trained-model.pt\n","Experiments.gsheet\t  Presentation.gslides\n"]}]},{"cell_type":"code","metadata":{"id":"mw7ZOt24fmNa","executionInfo":{"status":"ok","timestamp":1638558141022,"user_tz":300,"elapsed":155,"user":{"displayName":"Ameya Mahabaleshwarkar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWewArOnbcuIhn0zZGYi8CvzAMIgNfJVVvaTwTFg=s64","userId":"00795415078516995824"}}},"source":["cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if cuda else \"cpu\")\n","\n","resnet_model = resnet32()\n","resnet_model.to(device)\n","checkpoint = torch.load(\"/content/drive/MyDrive/11785 - Project/mnist-resnet-dynamic-adv-trained-model.pt\")\n","# mod_checkpoint = {k.replace(\"module.\", \"\"): v for k, v in checkpoint['state_dict'].items()}\n","resnet_model.load_state_dict(checkpoint[\"model_state_dict\"])\n","resnet_optimizer = torch.optim.SGD(resnet_model.parameters(), lr=0.1, weight_decay=5e-5, momentum=0.9)\n","resnet_criterion = nn.CrossEntropyLoss()\n","resnet_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(resnet_optimizer, T_0=10, T_mult=2, eta_min=0.01, last_epoch=-1)\n","\n","# output size at diff intermediate layers of resnet\n","interm_layer2dim = {1: 16, 2: 32, 3: 64}\n","interm_layer = 2\n","\n","subnet_model = SubNet(interm_layer2dim[interm_layer])\n","subnet_model.to(device)\n","subnet_optimizer = torch.optim.Adam(subnet_model.parameters(), lr=0.01, betas=(0.99, 0.999))\n","subnet_criterion = nn.BCELoss()\n","subnet_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(subnet_optimizer, T_0=10, T_mult=2, eta_min=0.01, last_epoch=-1)"],"execution_count":199,"outputs":[]},{"cell_type":"code","metadata":{"id":"5C6gKFHWfA3v","executionInfo":{"status":"ok","timestamp":1638558145456,"user_tz":300,"elapsed":214,"user":{"displayName":"Ameya Mahabaleshwarkar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWewArOnbcuIhn0zZGYi8CvzAMIgNfJVVvaTwTFg=s64","userId":"00795415078516995824"}}},"source":["def statically_train_subnet(\n","    resnet_model,\n","    interm_layer,\n","    subnet_model,\n","    subnet_optimizer,\n","    subnet_criterion,\n","    subnet_scheduler,\n","    unattacked_train_data,\n","    unattacked_test_data,\n","    attacked_train_data,\n","    attacked_test_data,\n","    device,\n","    epochs=100,\n","    batch_size=64,\n","):\n","    subnet_model.train()\n","    resnet_model.eval()\n","    batches = []\n","\n","    for epoch in range(epochs):\n","\n","      avg_loss = 0.0\n","      for batch_itr in tqdm(range(0, len(unattacked_train_data), batch_size)):\n","          attacked_input = attacked_train_data[batch_itr:batch_itr+batch_size]\n","          attacked_labels = torch.ones((attacked_input.shape[0], 1), dtype=torch.float32)\n","          unattacked_input = unattacked_train_data[batch_itr:batch_itr+batch_size]\n","          unattacked_labels = torch.zeros((unattacked_input.shape[0], 1), dtype=torch.float32)\n","\n","          input = torch.cat((unattacked_input, attacked_input), axis=0)\n","          labels = torch.cat((unattacked_labels, attacked_labels), axis=0)\n","\n","          assert input.shape[0] == labels.shape[0]\n","          shuffle_indices = np.arange(input.shape[0])\n","          np.random.shuffle(shuffle_indices)\n","          input, labels = input[shuffle_indices].squeeze(0), labels[shuffle_indices].squeeze(0)\n","\n","          input, labels = input.to(device), labels.to(device)\n","\n","          input = resnet_model(input.float(), return_interm_layer=interm_layer)\n","          output = subnet_model(input)\n","\n","          loss = subnet_criterion(output, labels)\n","          loss.backward()\n","          avg_loss += loss.item()\n","\n","          subnet_optimizer.step()\n","\n","          del input\n","          del labels\n","          del loss\n","          torch.cuda.empty_cache()\n","\n","      val_loss, val_acc, val_roc = statically_test_subnet(\n","          resnet_model,\n","          interm_layer,\n","          subnet_model,\n","          subnet_criterion,\n","          unattacked_test_data,\n","          attacked_test_data,\n","          device,\n","      )\n","\n","      print('Val Loss: {:.4f} | Val Accuracy: {:.4f} | Val ROC: {:.4f}'.format(val_loss, val_acc, val_roc))\n","      torch.save({\n","          'epoch': epoch,\n","          'model_state_dict': resnet_model.state_dict(),\n","          'optimizer_state_dict': subnet_optimizer.state_dict(),\n","      }, './' + str(epoch) + 'model.pt')"],"execution_count":200,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mo2QeuLkgWTo","executionInfo":{"status":"ok","timestamp":1638558146594,"user_tz":300,"elapsed":168,"user":{"displayName":"Ameya Mahabaleshwarkar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWewArOnbcuIhn0zZGYi8CvzAMIgNfJVVvaTwTFg=s64","userId":"00795415078516995824"}}},"source":["def statically_test_subnet(\n","    resnet_model,\n","    interm_layer,\n","    subnet_model,\n","    criterion,\n","    unattacked_test_data,\n","    attacked_test_data,\n","    device,\n","    batch_size=64,\n","):\n","    resnet_model.eval()\n","    subnet_model.eval()\n","    test_loss = []\n","    accuracies = []\n","    roc_scores = []\n","\n","    for batch_itr in tqdm(range(0, len(unattacked_test_data), batch_size)):\n","        attacked_input = attacked_test_data[batch_itr:batch_itr+batch_size]\n","        attacked_labels = torch.ones((attacked_input.shape[0], 1), dtype=torch.float32)\n","        unattacked_input = unattacked_test_data[batch_itr:batch_itr+batch_size]\n","        unattacked_labels = torch.zeros((unattacked_input.shape[0], 1), dtype=torch.float32)\n","\n","        input = torch.cat((unattacked_input, attacked_input), axis=0)\n","        labels = torch.cat((unattacked_labels, attacked_labels), axis=0)\n","\n","        assert input.shape[0] == labels.shape[0]\n","        shuffle_indices = np.arange(input.shape[0])\n","        np.random.shuffle(shuffle_indices)\n","        input, labels = input[shuffle_indices].squeeze(0), labels[shuffle_indices].squeeze(0)\n","\n","        input, labels = input.to(device), labels.to(device)\n","\n","        with torch.no_grad():\n","            input = resnet_model(input.float(), return_interm_layer=interm_layer)\n","            output = subnet_model(input)\n","\n","        pred_labels = (output > 0.5).float()\n","        loss = criterion(output, labels)\n","\n","        # print()\n","        # print(pred_labels.flatten())\n","        # print(labels.flatten())\n","        # print()\n","\n","        accuracy = accuracy_score(labels.flatten().cpu(), pred_labels.flatten().cpu())\n","        roc_score = roc_auc_score(labels.flatten().cpu(), pred_labels.flatten().cpu())\n","        accuracies.append(accuracy)\n","        roc_scores.append(roc_score)\n","        test_loss.extend([loss.item()]*input.size()[0])\n","        \n","        del input\n","        del labels\n","        del loss\n","        torch.cuda.empty_cache()\n","\n","    subnet_model.train()\n","\n","    return np.mean(test_loss), np.mean(accuracies), np.mean(roc_scores)"],"execution_count":201,"outputs":[]},{"cell_type":"code","metadata":{"id":"xixHtjZVR5f_","executionInfo":{"status":"ok","timestamp":1638558147981,"user_tz":300,"elapsed":183,"user":{"displayName":"Ameya Mahabaleshwarkar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWewArOnbcuIhn0zZGYi8CvzAMIgNfJVVvaTwTFg=s64","userId":"00795415078516995824"}}},"source":["def dynamically_train_subnet(\n","    resnet_model,\n","    interm_layer,\n","    subnet_model,\n","    subnet_optimizer,\n","    subnet_criterion,\n","    subnet_scheduler,\n","    benign_train_imgs,\n","    benign_test_imgs,\n","    device,\n","    epochs=100,\n","    batch_size=64,\n","):\n","    subnet_model.train()\n","    resnet_model.eval()\n","\n","    best_loss = float('inf')\n","    for epoch in range(epochs):\n","      \n","      avg_loss = 0.0\n","      for batch_itr in tqdm(range(0, len(benign_train_imgs), batch_size)):\n","\n","        # get resnet outputs of benign imgs and labels as '0'\n","        benign_inputs = benign_train_imgs[batch_itr:batch_itr+batch_size].float().to(device)\n","        benign_inputs = resnet_model(benign_inputs, return_interm_layer=interm_layer)\n","        benign_train_labels = torch.zeros((benign_inputs.shape[0], 1), dtype=torch.float32)\n","\n","        # create a attack instance using current state of the subnet\n","        train_attack = torchattacks.PGD(subnet_model, eps=4/255, alpha=1/255, steps=40)\n","        adv_inputs = train_attack(benign_inputs, benign_train_labels)\n","        adv_train_labels = torch.ones((adv_inputs.shape[0], 1), dtype=torch.float32)\n","\n","        # create a 2x batch with adv and benign images\n","        input = torch.cat((benign_inputs, adv_inputs), axis=0)\n","        labels = torch.cat((benign_train_labels, adv_train_labels), axis=0)\n","\n","        # shuffle the combined inputs and labels\n","        assert input.shape[0] == labels.shape[0]\n","        shuffle_indices = np.arange(input.shape[0])\n","        np.random.shuffle(shuffle_indices)\n","        input, labels = input[shuffle_indices].squeeze(0), labels[shuffle_indices].squeeze(0)\n","\n","        # feed to subnet\n","        input, labels = input.to(device), labels.to(device)\n","        output = subnet_model(input)\n","\n","        # calculate loss\n","        loss = subnet_criterion(output, labels)\n","        loss.backward()\n","        avg_loss += loss.item()\n","\n","        # param update\n","        subnet_optimizer.step()\n","\n","        # cleanup\n","        del input\n","        del labels\n","        del loss\n","        torch.cuda.empty_cache()\n","\n","      avg_loss /= len(benign_train_imgs)\n","\n","      val_loss, val_acc, val_roc = dynamically_test_subnet(\n","          resnet_model,\n","          interm_layer,\n","          subnet_model,\n","          subnet_criterion,\n","          benign_test_imgs,\n","          device,\n","      )\n","\n","      print('Train Loss: {:.4f} | Val Loss: {:.4f} | Val Accuracy: {:.4f} | Val ROC: {:.4f}'.format(avg_loss, val_loss, val_acc, val_roc))\n","      if val_loss > best_loss:\n","        best_loss = val_loss\n","        torch.save({\n","            'epoch': epoch,\n","            'model_state_dict': subnet_model.state_dict(),\n","            'optimizer_state_dict': subnet_optimizer.state_dict(),\n","        }, './' + str(epoch) + 'model.pt')\n","\n","      subnet_scheduler.step(val_loss)"],"execution_count":202,"outputs":[]},{"cell_type":"code","metadata":{"id":"kbAPinH0T_fB","executionInfo":{"status":"ok","timestamp":1638558148938,"user_tz":300,"elapsed":148,"user":{"displayName":"Ameya Mahabaleshwarkar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWewArOnbcuIhn0zZGYi8CvzAMIgNfJVVvaTwTFg=s64","userId":"00795415078516995824"}}},"source":["def dynamically_test_subnet(\n","    resnet_model,\n","    interm_layer,\n","    subnet_model,\n","    subnet_criterion,\n","    benign_test_imgs,\n","    device,\n","    batch_size=64,\n","    threshold=0.5,\n","):\n","    resnet_model.eval()\n","    subnet_model.eval()\n","    test_loss = []\n","    accuracies = []\n","    roc_scores = []\n","\n","    for batch_itr in tqdm(range(0, len(benign_test_imgs), batch_size)):\n","\n","        # get resnet outputs of benign imgs and labels as '0'\n","        benign_inputs = benign_test_imgs[batch_itr:batch_itr+batch_size].float().to(device)\n","        benign_inputs = resnet_model(benign_inputs, return_interm_layer=interm_layer)\n","        benign_test_labels = torch.zeros((benign_inputs.shape[0], 1), dtype=torch.float32)\n","        \n","        # create a attack instance using current state of the subnet\n","        val_attack = torchattacks.PGD(subnet_model, eps=2/255, alpha=1/255, steps=40)\n","        adv_inputs = val_attack(benign_inputs, benign_test_labels)\n","        adv_test_labels = torch.ones((adv_inputs.shape[0], 1), dtype=torch.float32)\n","\n","        # create a 2x batch with adv and benign images\n","        input = torch.cat((benign_inputs, adv_inputs), axis=0)\n","        labels = torch.cat((benign_test_labels, adv_test_labels), axis=0)\n","\n","        # shuffle the combined inputs and labels\n","        assert input.shape[0] == labels.shape[0]\n","        shuffle_indices = np.arange(input.shape[0])\n","        np.random.shuffle(shuffle_indices)\n","        input, labels = input[shuffle_indices].squeeze(0), labels[shuffle_indices].squeeze(0)\n","\n","        # feed to subnet\n","        input, labels = input.to(device), labels.to(device)\n","        with torch.no_grad():\n","            output = subnet_model(input)\n","\n","        # get labels based on threshold and calculate loss\n","        pred_labels = (output > threshold).float()\n","        loss = subnet_criterion(output, labels)\n","\n","        # calculate metrics\n","        accuracy = accuracy_score(labels.flatten().cpu(), pred_labels.flatten().cpu())\n","        accuracies.append(accuracy)\n","        roc_score = roc_auc_score(labels.flatten().cpu(), pred_labels.flatten().cpu())\n","        roc_scores.append(roc_score)\n","        test_loss.extend([loss.item()]*input.size()[0])\n","        \n","        # cleanup\n","        del input\n","        del labels\n","        del loss\n","        torch.cuda.empty_cache()\n","\n","    subnet_model.train()\n","\n","    return np.mean(test_loss), np.mean(accuracies), np.mean(roc_scores)"],"execution_count":203,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hu7KDO5DZGgp"},"source":["### Read Benign Data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4VhfAotEYd-j","executionInfo":{"status":"ok","timestamp":1638558152581,"user_tz":300,"elapsed":342,"user":{"displayName":"Ameya Mahabaleshwarkar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWewArOnbcuIhn0zZGYi8CvzAMIgNfJVVvaTwTFg=s64","userId":"00795415078516995824"}},"outputId":"3bd1b5dd-71fc-40c5-9293-4bb46f5506ea"},"source":["!ls '/content/drive/MyDrive/11785 - Project/data'"],"execution_count":204,"outputs":[{"output_type":"stream","name":"stdout","text":["benign_cifar.npy\t      fgsm_mnist_eps0.5.npy\n","benign_cifar_train.npy\t      pgd_cifar_default_art.npy\n","benign_mnist.npy\t      pgd_cifar_default_torchattacks_new.npy\n","benign_mnist_train.npy\t      pgd_cifar_eps0.1_torchattacks.npy\n","cwlinf_cifar_default_art.npy  pgd_cifar_eps0.3_alpha0.1_steps7.npy\n","cwlinf_default_art.npy\t      pgd_mnist_default_art.npy\n","cwlinf_mnist_default_art.npy  pgd_mnist_eps0.3_alpha0.1_steps7.npy\n","fgsm_cifar_default_art.npy\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E43gPXw_Yhps","executionInfo":{"status":"ok","timestamp":1638558225730,"user_tz":300,"elapsed":1027,"user":{"displayName":"Ameya Mahabaleshwarkar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWewArOnbcuIhn0zZGYi8CvzAMIgNfJVVvaTwTFg=s64","userId":"00795415078516995824"}},"outputId":"96a40303-4dea-4ed9-c62f-cadb65cf2bb1"},"source":["batch_size = 64\n","\n","# benign data\n","benign_imgs_path = \"/content/drive/MyDrive/11785 - Project/data/pgd_mnist_default_art.npy\"\n","benign_imgs = np.load(benign_imgs_path, allow_pickle=True).astype(float)\n","benign_imgs = torch.from_numpy(benign_imgs) # .transpose(0, 3, 1, 2))\n","shuffle_indices = np.arange(benign_imgs.shape[0])\n","np.random.shuffle(shuffle_indices)\n","benign_imgs = benign_imgs[shuffle_indices]\n","print(f\"benign data shape: {benign_imgs.shape}\")\n","\n","# train-test split\n","split_idx = 9000\n","benign_train_imgs = benign_imgs[:split_idx]\n","benign_test_imgs = benign_imgs[split_idx:]"],"execution_count":212,"outputs":[{"output_type":"stream","name":"stdout","text":["benign data shape: torch.Size([10000, 1, 28, 28])\n"]}]},{"cell_type":"markdown","metadata":{"id":"KNrIUMbmZNtg"},"source":["### Load Base Model - ResNet"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"422VZVAaZKp_","executionInfo":{"status":"ok","timestamp":1638558225913,"user_tz":300,"elapsed":186,"user":{"displayName":"Ameya Mahabaleshwarkar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWewArOnbcuIhn0zZGYi8CvzAMIgNfJVVvaTwTFg=s64","userId":"00795415078516995824"}},"outputId":"ec925271-98c7-42d8-b613-47ab9804e306"},"source":["! ls \"/content/drive/MyDrive/11785 - Project/\""],"execution_count":213,"outputs":[{"output_type":"stream","name":"stdout","text":["AdversarialDetection.pdf  imgs\n","cifar10_model.pth\t  mnist_model.pth\n","data\t\t\t  mnist-resnet-dynamic-adv-trained-model.pt\n","Experiments.gsheet\t  Presentation.gslides\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wjRMc5TtZRLu","executionInfo":{"status":"ok","timestamp":1638558226096,"user_tz":300,"elapsed":185,"user":{"displayName":"Ameya Mahabaleshwarkar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWewArOnbcuIhn0zZGYi8CvzAMIgNfJVVvaTwTFg=s64","userId":"00795415078516995824"}},"outputId":"7bce6b95-6b3a-46d5-ff82-b3aa22f38de5"},"source":["cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if cuda else \"cpu\")\n","\n","resnet_model = resnet32()\n","resnet_model.to(device)\n","# checkpoint = torch.load(\"/content/drive/MyDrive/11785 - Project/resnet-adv-trained-model.pt\", map_location=device)\n","checkpoint = torch.load(\"/content/drive/MyDrive/11785 - Project/mnist-resnet-dynamic-adv-trained-model.pt\", map_location=device)\n","resnet_model.load_state_dict(checkpoint[\"model_state_dict\"])\n","# resnet_model.load_state_dict(checkpoint)"],"execution_count":214,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":214}]},{"cell_type":"markdown","metadata":{"id":"J0uU_mt2Za4C"},"source":["### Create SubNet"]},{"cell_type":"code","metadata":{"id":"8ljAeRdgZc-s","executionInfo":{"status":"ok","timestamp":1638558226795,"user_tz":300,"elapsed":3,"user":{"displayName":"Ameya Mahabaleshwarkar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWewArOnbcuIhn0zZGYi8CvzAMIgNfJVVvaTwTFg=s64","userId":"00795415078516995824"}}},"source":["# output size at diff intermediate layers of resnet\n","interm_layer2dim = {1: 16, 2: 32, 3: 64}\n","interm_layer = 2\n","\n","subnet_model = SubNet(interm_layer2dim[interm_layer])\n","subnet_model.to(device)\n","subnet_optimizer = torch.optim.Adam(subnet_model.parameters(), lr=0.0001, betas=(0.99, 0.999))\n","subnet_criterion = nn.BCEWithLogitsLoss()\n","subnet_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(subnet_optimizer, 'min', factor=0.75, patience=1)"],"execution_count":215,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GAaJqpImZwek"},"source":["### Run Training"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":431,"referenced_widgets":["45c8566feef64d5d8bae97d8e6aeeaf7","a0c61a5da8c64859a6cc45b5258d4496","3133bd70f1db4e11bd4b1a9f21d6f952","6b06af96543b4d748bf3c42eb600f2f1","c5bbeb069c764dc9a7d546b137b77010","955197ae153649d6896dd6c2a4b5793f","90136e23b0834ccf9d1c930c6885cd71","e5e1a7d5067b43a39516312907cbc8d9","9bcdce1956dc41bea05f795ee7c3f4b9","ef94712fb7bf46e991d5c24a38275002","3bd9d8cbf34241ea90b542ef70b18c80","077035c79e6f4c088ce3080ccd924a43","4dbfcb77ecb24d1bbfc50cc879c0fb4c","166fe3c004bd40cd8d6cc1244ca1d5ec","5444ccf1f3e6427cbad50acf5c88879c","b603387bd50f47e3943958085f3e2fc4","60bf0bf14c664283b7c6736f4e64ede2","db8a9f06d34b45be8112c1596b9a1f0b","9580d6851d39420bac15fe04a74e3478","6d33132eb71e4b0abca6509326881138","5c7b6598b67049c19cdebdc21226e39a","a474febabd034853b862b28413533180","71fcddd87ab44b0fb68cc188c34fa990","8055326fc1b74d5b88f7d5a8f81d8aab","80b3c9d053994bfb84181fa188583ea5","f9679077cf434ea1b0a54aa470008ace","468fa5e692d546d1ab276f0edb2a1233","355e40f871e9413888d1bfc6b2955272","7ce6477765ff4c31a9688121a74d4911","f253670703024f2a92c6638e2ec2464f","6c650b0b4dc043278c8e47c34ad242a7","2add25ed869e432491c61a9c2136171e","e303c681f6ba432983eb69adb062038a","b9a4b0ba3cec40769680e93e4e81624b","b69042a0c34a4d029392de61b9757867","a3b3b06fcfb347b39454475c4265a21b","976983f0c4564b538ec4e085b06c1246","68c3c3c5e2ba457290fb878205e0b11d","7ea40c89da234b4386be0c6286d5060c","23612e281c754a1eb385be56b38b59cc","626c7ae78525420c99670394f5d075f6","347400c9ae04423ea33d86d98d84d884","202a517ea2bc42c284d259a7e9788a29","a7142eaee32e4b7397ca4dd04736a5a3","0d27b0baf68745c5afab331d0b522745","927e1ff9f71548fdaa45f48d196bb04e","35aafb90d3424079b453ef83a5d2df0b","5bed852efc704e378a8eec4a91c2ec35","2b7cff8ca75b4a529af0d561b74eedfc","617c86fede034d0ab6bb13b315afd8ad","4ade0433e5ef4fdbba6cae00b2bc5ca7","72d84ae7a6aa455c979a039c393ed6b7","a2e2b27749db478f8d756404e79e155f","b252fae49bc748abbea71ee5eed2f968","2e0358c4418c4ed4b23d5b103156b44c","fec1c006dc5941d39520035e46f9c91b","d0ce4f5ede9c4bed86021537d75ed81d","8ab54aefe8f645af949c952d73be716e","262a1df2157f463abe0ba686d6efee1c","7e4e4b49922745ba9a5126147339e34d","b1bae2dd3c28490cab92670a44c9324e","a29c3ac6510a433983eb7fbb0bfe8489","38877e1c51a142ba84735582b93ce40a","9d14497226954b15a8c074c5747b3e29","564f1c197f62469c836be509990308ab","658d27a4cfc34ea49aee8045ef8ce3a3","50b492ea29574976939eded9fa077b45","5066aa757ffd425e95e5d46c49716674","58ae97416c3d4a20bef849538872f08b","b8295289c9b8433aafb050ad57193ea1","1f29083b692c4faa91a3d8e1a5e5bae8","01f00600d33d457a86fe5ab7988daddb","f787a63920ea4175a1f7ae2312851bc5","90eaaf2216334c5fbca178bdf021b73d","c9a5ed36fdee4923bec98f5d228e64ab","371df42248bc4109845e9265c6385d2f","16019ab234dc4dc09beae1076baa6c74","f50ace8573c54d3da27c641e93ce8928","1d18eaf3eee746518242983d5f5cfd58","27db5ceef9c8482fbf76984fdb57af34","f7d406910994469bba32d19324754392","e28246f458ee487eb4211444e4278505","1d56d1f9acd7480092c5c5f1f9ece54c","cfcb275b83314e849c7ce0e6c562d8a0","d20dc351c2b44b599b49ad2f1ba86cc1","a5d995942029462fb5284eb4ddbcc80f","bdf409402fc24c8cbf92a426a5695368","440cdeaaafd440178ae153995fe03061","928d89ecbd9e483bbdb6c67e4d00e60a","56c3ee3f29b24dcabe7712748bfeaba7","f6ab69c0f6e542ba8390eb23e371f680","84492d2e06fc479794fd6c6211c5a796","5d52d802719c40d5b4a2944c774f66b5","1b4bebd5a1c546eab758f904eda1395a","0bc90379304f4ed5a6d750bfbbac607d","94f897019fce4028965701e513d49fd2","aabc47efdedb431dad82bef35da37827","33199ff45aa34cf39bd7c67bf9b55e58","fc2910224daa49429167fc6bf42d8b52","fb987c7fe98e41939086fd2fa4d42376","e693b5d83162416a9ccfde153eb07290","770a5df2e80b4f1ca38ae86bde46e2c8","7f3b6f585d4645219a11244753e83684","56e48d92117a4b8faaa7bc3682ca2c8e","04675d3794bc4910a3a079de3f76d08d","855d99d9017d4dba951c5ee892910bec","a657a4a421704c3bb615648e2d2b425d","00682514031d469baf77bfb08d3c6e6a","f8990627b19b4a64b978b7aa32a37225","2392e6347b8f44af97a2968579501d89"]},"id":"0g8hEdD-Zx9N","executionInfo":{"status":"ok","timestamp":1638558353903,"user_tz":300,"elapsed":125779,"user":{"displayName":"Ameya Mahabaleshwarkar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWewArOnbcuIhn0zZGYi8CvzAMIgNfJVVvaTwTFg=s64","userId":"00795415078516995824"}},"outputId":"262892bf-fa89-4e39-9739-5e336606fcfa"},"source":["dynamically_train_subnet(\n","  resnet_model,\n","  interm_layer,\n","  subnet_model,\n","  subnet_optimizer,\n","  subnet_criterion,\n","  subnet_scheduler,\n","  benign_train_imgs,\n","  benign_test_imgs,\n","  device,\n","  epochs=5,\n","  batch_size=64,\n",")"],"execution_count":216,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"45c8566feef64d5d8bae97d8e6aeeaf7","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/141 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"077035c79e6f4c088ce3080ccd924a43","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/16 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.0104 | Val Loss: 0.6585 | Val Accuracy: 1.0000 | Val ROC: 1.0000\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"71fcddd87ab44b0fb68cc188c34fa990","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/141 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b9a4b0ba3cec40769680e93e4e81624b","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/16 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.0103 | Val Loss: 0.6563 | Val Accuracy: 1.0000 | Val ROC: 1.0000\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0d27b0baf68745c5afab331d0b522745","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/141 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fec1c006dc5941d39520035e46f9c91b","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/16 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.0103 | Val Loss: 0.6531 | Val Accuracy: 1.0000 | Val ROC: 1.0000\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"50b492ea29574976939eded9fa077b45","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/141 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f50ace8573c54d3da27c641e93ce8928","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/16 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.0102 | Val Loss: 0.6495 | Val Accuracy: 1.0000 | Val ROC: 1.0000\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"928d89ecbd9e483bbdb6c67e4d00e60a","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/141 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fb987c7fe98e41939086fd2fa4d42376","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/16 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.0102 | Val Loss: 0.6459 | Val Accuracy: 1.0000 | Val ROC: 1.0000\n"]}]},{"cell_type":"code","metadata":{"id":"dqUU_dp_gDoZ"},"source":["statically_train_subnet(\n","    resnet_model,\n","    interm_layer,\n","    subnet_model,\n","    subnet_optimizer,\n","    subnet_criterion,\n","    subnet_scheduler,\n","    unattacked_train_data,\n","    unattacked_test_data,\n","    attacked_train_data,\n","    attacked_test_data,\n","    device,\n","    epochs=5,\n","    batch_size=64,\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iSCuMh6ZTlgt"},"source":["### Combined PGD Attack"]},{"cell_type":"code","metadata":{"id":"75b0P-LqTdrW","executionInfo":{"status":"ok","timestamp":1638558360999,"user_tz":300,"elapsed":215,"user":{"displayName":"Ameya Mahabaleshwarkar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWewArOnbcuIhn0zZGYi8CvzAMIgNfJVVvaTwTFg=s64","userId":"00795415078516995824"}}},"source":["from art.attacks.evasion import FastGradientMethod, ProjectedGradientDescentPyTorch, CarliniLInfMethod, SaliencyMapMethod, DeepFool\n","from art.estimators.classification import PyTorchClassifier\n","from art.utils import load_mnist, load_cifar10\n","from art.utils import load_dataset"],"execution_count":217,"outputs":[]},{"cell_type":"code","metadata":{"id":"mTOzYqNnUING","executionInfo":{"status":"ok","timestamp":1638558410806,"user_tz":300,"elapsed":1046,"user":{"displayName":"Ameya Mahabaleshwarkar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWewArOnbcuIhn0zZGYi8CvzAMIgNfJVVvaTwTFg=s64","userId":"00795415078516995824"}}},"source":["# benign = load_cifar10()\n","benign = load_mnist()\n","# (x_train, y_train), (x_test, y_test), min_pixel_value, max_pixel_value = load_cifar10()\n","(x_train, y_train), (x_test, y_test), min_pixel_value, max_pixel_value = load_mnist()"],"execution_count":225,"outputs":[]},{"cell_type":"code","metadata":{"id":"U7lNIACtTssQ","executionInfo":{"status":"ok","timestamp":1638558411344,"user_tz":300,"elapsed":540,"user":{"displayName":"Ameya Mahabaleshwarkar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWewArOnbcuIhn0zZGYi8CvzAMIgNfJVVvaTwTFg=s64","userId":"00795415078516995824"}}},"source":["class AttackCombined(object):\n","    r\"\"\"\n","    Base class for all attacks.\n","    .. note::\n","        It automatically set device to the device where given model is.\n","        It basically changes training mode to eval during attack process.\n","        To change this, please see `set_training_mode`.\n","    \"\"\"\n","    def __init__(self, name, model, detector_model):\n","        r\"\"\"\n","        Initializes internal attack state.\n","        Arguments:\n","            name (str): name of attack.\n","            model (torch.nn.Module): model to attack.\n","        \"\"\"\n","\n","        self.attack = name\n","        self.model = model\n","        self.detector = detector_model\n","        self.model_name = str(model).split(\"(\")[0]\n","        self.device = next(model.parameters()).device\n","\n","        self._attack_mode = 'default'\n","        self._targeted = False\n","        self._return_type = 'float'\n","        self._supported_mode = ['default']\n","\n","        self._model_training = False\n","        self._batchnorm_training = False\n","        self._dropout_training = False\n","\n","    def forward(self, *input):\n","        r\"\"\"\n","        It defines the computation performed at every call.\n","        Should be overridden by all subclasses.\n","        \"\"\"\n","        raise NotImplementedError\n","\n","    def get_mode(self):\n","        r\"\"\"\n","        Get attack mode.\n","        \"\"\"\n","        return self._attack_mode\n","\n","    def set_mode_default(self):\n","        r\"\"\"\n","        Set attack mode as default mode.\n","        \"\"\"\n","        self._attack_mode = 'default'\n","        self._targeted = False\n","        print(\"Attack mode is changed to 'default.'\")\n","\n","    def set_mode_targeted_by_function(self, target_map_function=None):\n","        r\"\"\"\n","        Set attack mode as targeted.\n","        Arguments:\n","            target_map_function (function): Label mapping function.\n","                e.g. lambda images, labels:(labels+1)%10.\n","                None for using input labels as targeted labels. (Default)\n","        \"\"\"\n","        if \"targeted\" not in self._supported_mode:\n","            raise ValueError(\"Targeted mode is not supported.\")\n","\n","        self._attack_mode = 'targeted'\n","        self._targeted = True\n","        self._target_map_function = target_map_function\n","        print(\"Attack mode is changed to 'targeted.'\")\n","\n","    def set_mode_targeted_least_likely(self, kth_min=1):\n","        r\"\"\"\n","        Set attack mode as targeted with least likely labels.\n","        Arguments:\n","            kth_min (str): label with the k-th smallest probability used as target labels. (Default: 1)\n","        \"\"\"\n","        if \"targeted\" not in self._supported_mode:\n","            raise ValueError(\"Targeted mode is not supported.\")\n","\n","        self._attack_mode = \"targeted(least-likely)\"\n","        self._targeted = True\n","        self._kth_min = kth_min\n","        self._target_map_function = self._get_least_likely_label\n","        print(\"Attack mode is changed to 'targeted(least-likely).'\")\n","\n","    def set_mode_targeted_random(self, n_classses=None):\n","        r\"\"\"\n","        Set attack mode as targeted with random labels.\n","        Arguments:\n","            num_classses (str): number of classes.\n","        \"\"\"\n","        if \"targeted\" not in self._supported_mode:\n","            raise ValueError(\"Targeted mode is not supported.\")\n","\n","        self._attack_mode = \"targeted(random)\"\n","        self._targeted = True\n","        self._n_classses = n_classses\n","        self._target_map_function = self._get_random_target_label\n","        print(\"Attack mode is changed to 'targeted(random).'\")\n","\n","    def set_return_type(self, type):\n","        r\"\"\"\n","        Set the return type of adversarial images: `int` or `float`.\n","        Arguments:\n","            type (str): 'float' or 'int'. (Default: 'float')\n","        .. note::\n","            If 'int' is used for the return type, the file size of \n","            adversarial images can be reduced (about 1/4 for CIFAR10).\n","            However, if the attack originally outputs float adversarial images\n","            (e.g. using small step-size than 1/255), it might reduce the attack\n","            success rate of the attack.\n","        \"\"\"\n","        if type == 'float':\n","            self._return_type = 'float'\n","        elif type == 'int':\n","            self._return_type = 'int'\n","        else:\n","            raise ValueError(type + \" is not a valid type. [Options: float, int]\")\n","\n","    def set_training_mode(self, model_training=False, batchnorm_training=False, dropout_training=False):\n","        r\"\"\"\n","        Set training mode during attack process.\n","        Arguments:\n","            model_training (bool): True for using training mode for the entire model during attack process.\n","            batchnorm_training (bool): True for using training mode for batchnorms during attack process.\n","            dropout_training (bool): True for using training mode for dropouts during attack process.\n","        .. note::\n","            For RNN-based models, we cannot calculate gradients with eval mode.\n","            Thus, it should be changed to the training mode during the attack.\n","        \"\"\"\n","        self._model_training = model_training\n","        self._batchnorm_training = batchnorm_training\n","        self._dropout_training = dropout_training\n","\n","    def save(self, data_loader, save_path=None, verbose=True, return_verbose=False):\n","        r\"\"\"\n","        Save adversarial images as torch.tensor from given torch.utils.data.DataLoader.\n","        Arguments:\n","            save_path (str): save_path.\n","            data_loader (torch.utils.data.DataLoader): data loader.\n","            verbose (bool): True for displaying detailed information. (Default: True)\n","            return_verbose (bool): True for returning detailed information. (Default: False)\n","        \"\"\"\n","        if (verbose==False) and (return_verbose==True):\n","            raise ValueError(\"Verobse should be True if return_verbose==True.\")\n","            \n","        if save_path is not None:\n","            image_list = []\n","            label_list = []\n","\n","        correct = 0\n","        total = 0\n","        l2_distance = []\n","\n","        total_batch = len(data_loader)\n","\n","        given_training = self.model.training\n","\n","        for step, (images, labels) in enumerate(data_loader):\n","            start = time.time()\n","            adv_images = self.__call__(images, labels)\n","\n","            batch_size = len(images)\n","\n","            if save_path is not None:\n","                image_list.append(adv_images.cpu())\n","                label_list.append(labels.cpu())\n","\n","            if self._return_type == 'int':\n","                adv_images = adv_images.float()/255\n","\n","            if verbose:\n","                with torch.no_grad():\n","                    if given_training:\n","                        self.model.eval()\n","                    outputs = self.model(adv_images)\n","                    _, predicted = torch.max(outputs.data, 1)\n","                    total += labels.size(0)\n","                    right_idx = (predicted == labels.to(self.device))\n","                    correct += right_idx.sum()\n","                    end = time.time()\n","                    delta = (adv_images - images.to(self.device)).view(batch_size, -1)\n","                    l2_distance.append(torch.norm(delta[~right_idx], p=2, dim=1))\n","\n","                    rob_acc = 100 * float(correct) / total\n","                    l2 = torch.cat(l2_distance).mean().item()\n","                    progress = (step+1)/total_batch*100\n","                    elapsed_time = end-start\n","                    self._save_print(progress, rob_acc, l2, elapsed_time, end='\\r')\n","\n","        # To avoid erasing the printed information.\n","        if verbose:\n","            self._save_print(progress, rob_acc, l2, elapsed_time, end='\\n')\n","\n","        if save_path is not None:\n","            x = torch.cat(image_list, 0)\n","            y = torch.cat(label_list, 0)\n","            torch.save((x, y), save_path)\n","            print('- Save complete!')\n","\n","        if given_training:\n","            self.model.train()\n","\n","        if return_verbose:\n","            return rob_acc, l2, elapsed_time\n","\n","    def _save_print(self, progress, rob_acc, l2, elapsed_time, end):\n","        print('- Save progress: %2.2f %% / Robust accuracy: %2.2f %% / L2: %1.5f (%2.3f it/s) \\t' \\\n","              % (progress, rob_acc, l2, elapsed_time), end=end)\n","\n","    def _get_target_label(self, images, labels=None):\n","        r\"\"\"\n","        Function for changing the attack mode.\n","        Return input labels.\n","        \"\"\"\n","        if self._target_map_function:\n","            return self._target_map_function(images, labels)\n","        raise ValueError('Please define target_map_function.')\n","\n","    def _get_least_likely_label(self, images, labels=None):\n","        r\"\"\"\n","        Function for changing the attack mode.\n","        Return least likely labels.\n","        \"\"\"\n","        outputs = self.model(images)\n","        if self._kth_min < 0:\n","            pos = outputs.shape[1] + self._kth_min + 1\n","        else:\n","            pos = self._kth_min\n","        _, target_labels = torch.kthvalue(outputs.data, pos)\n","        target_labels = target_labels.detach()\n","        return target_labels.long().to(self.device)\n","\n","    def _get_random_target_label(self, images, labels=None):\n","        if self._n_classses is None:\n","            outputs = self.model(images)\n","            if labels is None:\n","                _, labels = torch.max(outputs, dim=1)\n","            n_classses = outputs.shape[-1]\n","        else:\n","            n_classses = self._n_classses\n","\n","        target_labels = torch.zeros_like(labels)\n","        for counter in range(labels.shape[0]):\n","            l = list(range(n_classses))\n","            l.remove(labels[counter])\n","            t = self.random_int(0, len(l))\n","            target_labels[counter] = l[t]\n","\n","        return target_labels.long().to(self.device)\n","    \n","    def random_int(self, low=0, high=1, shape=[1]):\n","        t = low + (high - low) * torch.rand(shape).to(self.device)\n","        return t.long()\n","\n","    def _to_uint(self, images):\n","        r\"\"\"\n","        Function for changing the return type.\n","        Return images as int.\n","        \"\"\"\n","        return (images*255).type(torch.uint8)\n","\n","    def __str__(self):\n","        info = self.__dict__.copy()\n","\n","        del_keys = ['model', 'attack']\n","\n","        for key in info.keys():\n","            if key[0] == \"_\":\n","                del_keys.append(key)\n","\n","        for key in del_keys:\n","            del info[key]\n","\n","        info['attack_mode'] = self._attack_mode\n","        info['return_type'] = self._return_type\n","\n","        return self.attack + \"(\" + ', '.join('{}={}'.format(key, val) for key, val in info.items()) + \")\"\n","\n","    def __call__(self, *input, **kwargs):\n","        given_training = self.model.training\n","\n","        if self._model_training:\n","            self.model.train()\n","            for _, m in self.model.named_modules():\n","                if not self._batchnorm_training:\n","                    if 'BatchNorm' in m.__class__.__name__:\n","                        m = m.eval()\n","                if not self._dropout_training:\n","                    if 'Dropout' in m.__class__.__name__:\n","                        m = m.eval()\n","\n","        else:\n","            self.model.eval()\n","\n","        images = self.forward(*input, **kwargs)\n","\n","        if given_training:\n","            self.model.train()\n","\n","        if self._return_type == 'int':\n","            images = self._to_uint(images)\n","\n","        return images"],"execution_count":226,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z6nzxkvnTxa7","executionInfo":{"status":"ok","timestamp":1638558411345,"user_tz":300,"elapsed":7,"user":{"displayName":"Ameya Mahabaleshwarkar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWewArOnbcuIhn0zZGYi8CvzAMIgNfJVVvaTwTFg=s64","userId":"00795415078516995824"}}},"source":["import torch\n","import torch.nn as nn\n","\n","class PGDCombined(AttackCombined):\n","    r\"\"\"\n","    PGD in the paper 'Towards Deep Learning Models Resistant to Adversarial Attacks'\n","    [https://arxiv.org/abs/1706.06083]\n","\n","    Distance Measure : Linf\n","\n","    Arguments:\n","        model (nn.Module): model to attack.\n","        eps (float): maximum perturbation. (Default: 0.3)\n","        alpha (float): step size. (Default: 2/255)\n","        steps (int): number of steps. (Default: 40)\n","        random_start (bool): using random initialization of delta. (Default: True)\n","\n","    Shape:\n","        - images: :math:`(N, C, H, W)` where `N = number of batches`, `C = number of channels`,        `H = height` and `W = width`. It must have a range [0, 1].\n","        - labels: :math:`(N)` where each value :math:`y_i` is :math:`0 \\leq y_i \\leq` `number of labels`.\n","        - output: :math:`(N, C, H, W)`.\n","\n","    Examples::\n","        >>> attack = torchattacks.PGD(model, eps=8/255, alpha=1/255, steps=40, random_start=True)\n","        >>> adv_images = attack(images, labels)\n","\n","    \"\"\"\n","    def __init__(\n","        self,\n","        base_model,\n","        detector_model,\n","        eps=0.3,\n","        alpha=2/255,\n","        steps=40,\n","        random_start=True,\n","    ):\n","        super().__init__(\"PGD\", base_model, detector_model)\n","        self.eps = eps\n","        self.alpha = alpha\n","        self.steps = steps\n","        self.random_start = random_start\n","        self._supported_mode = ['default', 'targeted']\n","\n","    def forward(self, images, labels):\n","        r\"\"\"\n","        Overridden.\n","        \"\"\"\n","        images = images.clone().detach().to(self.device)\n","        labels = labels.clone().detach().to(self.device)\n","\n","        if self._targeted:\n","            target_labels = self._get_target_label(images, labels)\n","\n","        loss1 = nn.CrossEntropyLoss()\n","        loss2 = nn.BCEWithLogitsLoss()\n","\n","        adv_images = images.clone().detach()\n","\n","        if self.random_start:\n","            # Starting at a uniformly random point\n","            adv_images = adv_images + torch.empty_like(adv_images).uniform_(-self.eps, self.eps)\n","            adv_images = torch.clamp(adv_images, min=0, max=1).detach()\n","\n","        for _ in range(self.steps):\n","            adv_images.requires_grad = True\n","            outputs1 = self.model(adv_images.float())\n","            interm_outputs = self.model(adv_images.float(), return_interm_layer=interm_layer)\n","            outputs2 = self.detector(interm_outputs)\n","\n","            discount_factor = 0.7\n","\n","            base_classifier_loss = loss1(outputs1, labels)\n","            subnetwork_loss = loss2(outputs2, torch.ones(labels.shape[0], 1))\n","\n","            # Calculate loss\n","            if self._targeted:\n","                # cost = -loss(outputs, target_labels)\n","                cost = -base_classifier_loss + -subnetwork_loss\n","            else:\n","                # cost = loss(outputs, labels)\n","                cost = base_classifier_loss + subnetwork_loss\n","                # cost = subnetwork_loss\n","\n","            print(f\"cost: {cost} | base classifier loss: {base_classifier_loss} | subnet loss: {subnetwork_loss}\")\n","\n","            # Update adversarial images\n","            grad = torch.autograd.grad(cost, adv_images,\n","                                       retain_graph=False, create_graph=False)[0]\n","\n","            adv_images = adv_images.detach() + self.alpha*grad.sign()\n","            delta = torch.clamp(adv_images - images, min=-self.eps, max=self.eps)\n","            adv_images = torch.clamp(images + delta, min=0, max=1).detach()\n","\n","        return adv_images"],"execution_count":227,"outputs":[]},{"cell_type":"code","metadata":{"id":"GZLBmn7YnTpa","executionInfo":{"status":"ok","timestamp":1638558412115,"user_tz":300,"elapsed":775,"user":{"displayName":"Ameya Mahabaleshwarkar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWewArOnbcuIhn0zZGYi8CvzAMIgNfJVVvaTwTFg=s64","userId":"00795415078516995824"}}},"source":["class SingleAttack(object):\n","    r\"\"\"\n","    Base class for all attacks.\n","    .. note::\n","        It automatically set device to the device where given model is.\n","        It basically changes training mode to eval during attack process.\n","        To change this, please see `set_training_mode`.\n","    \"\"\"\n","    def __init__(self, name, model):\n","        r\"\"\"\n","        Initializes internal attack state.\n","        Arguments:\n","            name (str): name of attack.\n","            model (torch.nn.Module): model to attack.\n","        \"\"\"\n","\n","        self.attack = name\n","        self.model = model\n","        self.model_name = str(model).split(\"(\")[0]\n","        self.device = next(model.parameters()).device\n","\n","        self._attack_mode = 'default'\n","        self._targeted = False\n","        self._return_type = 'float'\n","        self._supported_mode = ['default']\n","\n","        self._model_training = False\n","        self._batchnorm_training = False\n","        self._dropout_training = False\n","\n","    def forward(self, *input):\n","        r\"\"\"\n","        It defines the computation performed at every call.\n","        Should be overridden by all subclasses.\n","        \"\"\"\n","        raise NotImplementedError\n","\n","    def get_mode(self):\n","        r\"\"\"\n","        Get attack mode.\n","        \"\"\"\n","        return self._attack_mode\n","\n","    def set_mode_default(self):\n","        r\"\"\"\n","        Set attack mode as default mode.\n","        \"\"\"\n","        self._attack_mode = 'default'\n","        self._targeted = False\n","        print(\"Attack mode is changed to 'default.'\")\n","\n","    def set_mode_targeted_by_function(self, target_map_function=None):\n","        r\"\"\"\n","        Set attack mode as targeted.\n","        Arguments:\n","            target_map_function (function): Label mapping function.\n","                e.g. lambda images, labels:(labels+1)%10.\n","                None for using input labels as targeted labels. (Default)\n","        \"\"\"\n","        if \"targeted\" not in self._supported_mode:\n","            raise ValueError(\"Targeted mode is not supported.\")\n","\n","        self._attack_mode = 'targeted'\n","        self._targeted = True\n","        self._target_map_function = target_map_function\n","        print(\"Attack mode is changed to 'targeted.'\")\n","\n","    def set_mode_targeted_least_likely(self, kth_min=1):\n","        r\"\"\"\n","        Set attack mode as targeted with least likely labels.\n","        Arguments:\n","            kth_min (str): label with the k-th smallest probability used as target labels. (Default: 1)\n","        \"\"\"\n","        if \"targeted\" not in self._supported_mode:\n","            raise ValueError(\"Targeted mode is not supported.\")\n","\n","        self._attack_mode = \"targeted(least-likely)\"\n","        self._targeted = True\n","        self._kth_min = kth_min\n","        self._target_map_function = self._get_least_likely_label\n","        print(\"Attack mode is changed to 'targeted(least-likely).'\")\n","\n","    def set_mode_targeted_random(self, n_classses=None):\n","        r\"\"\"\n","        Set attack mode as targeted with random labels.\n","        Arguments:\n","            num_classses (str): number of classes.\n","        \"\"\"\n","        if \"targeted\" not in self._supported_mode:\n","            raise ValueError(\"Targeted mode is not supported.\")\n","\n","        self._attack_mode = \"targeted(random)\"\n","        self._targeted = True\n","        self._n_classses = n_classses\n","        self._target_map_function = self._get_random_target_label\n","        print(\"Attack mode is changed to 'targeted(random).'\")\n","\n","    def set_return_type(self, type):\n","        r\"\"\"\n","        Set the return type of adversarial images: `int` or `float`.\n","        Arguments:\n","            type (str): 'float' or 'int'. (Default: 'float')\n","        .. note::\n","            If 'int' is used for the return type, the file size of \n","            adversarial images can be reduced (about 1/4 for CIFAR10).\n","            However, if the attack originally outputs float adversarial images\n","            (e.g. using small step-size than 1/255), it might reduce the attack\n","            success rate of the attack.\n","        \"\"\"\n","        if type == 'float':\n","            self._return_type = 'float'\n","        elif type == 'int':\n","            self._return_type = 'int'\n","        else:\n","            raise ValueError(type + \" is not a valid type. [Options: float, int]\")\n","\n","    def set_training_mode(self, model_training=False, batchnorm_training=False, dropout_training=False):\n","        r\"\"\"\n","        Set training mode during attack process.\n","        Arguments:\n","            model_training (bool): True for using training mode for the entire model during attack process.\n","            batchnorm_training (bool): True for using training mode for batchnorms during attack process.\n","            dropout_training (bool): True for using training mode for dropouts during attack process.\n","        .. note::\n","            For RNN-based models, we cannot calculate gradients with eval mode.\n","            Thus, it should be changed to the training mode during the attack.\n","        \"\"\"\n","        self._model_training = model_training\n","        self._batchnorm_training = batchnorm_training\n","        self._dropout_training = dropout_training\n","\n","    def save(self, data_loader, save_path=None, verbose=True, return_verbose=False):\n","        r\"\"\"\n","        Save adversarial images as torch.tensor from given torch.utils.data.DataLoader.\n","        Arguments:\n","            save_path (str): save_path.\n","            data_loader (torch.utils.data.DataLoader): data loader.\n","            verbose (bool): True for displaying detailed information. (Default: True)\n","            return_verbose (bool): True for returning detailed information. (Default: False)\n","        \"\"\"\n","        if (verbose==False) and (return_verbose==True):\n","            raise ValueError(\"Verobse should be True if return_verbose==True.\")\n","            \n","        if save_path is not None:\n","            image_list = []\n","            label_list = []\n","\n","        correct = 0\n","        total = 0\n","        l2_distance = []\n","\n","        total_batch = len(data_loader)\n","\n","        given_training = self.model.training\n","\n","        for step, (images, labels) in enumerate(data_loader):\n","            start = time.time()\n","            adv_images = self.__call__(images, labels)\n","\n","            batch_size = len(images)\n","\n","            if save_path is not None:\n","                image_list.append(adv_images.cpu())\n","                label_list.append(labels.cpu())\n","\n","            if self._return_type == 'int':\n","                adv_images = adv_images.float()/255\n","\n","            if verbose:\n","                with torch.no_grad():\n","                    if given_training:\n","                        self.model.eval()\n","                    outputs = self.model(adv_images)\n","                    _, predicted = torch.max(outputs.data, 1)\n","                    total += labels.size(0)\n","                    right_idx = (predicted == labels.to(self.device))\n","                    correct += right_idx.sum()\n","                    end = time.time()\n","                    delta = (adv_images - images.to(self.device)).view(batch_size, -1)\n","                    l2_distance.append(torch.norm(delta[~right_idx], p=2, dim=1))\n","\n","                    rob_acc = 100 * float(correct) / total\n","                    l2 = torch.cat(l2_distance).mean().item()\n","                    progress = (step+1)/total_batch*100\n","                    elapsed_time = end-start\n","                    self._save_print(progress, rob_acc, l2, elapsed_time, end='\\r')\n","\n","        # To avoid erasing the printed information.\n","        if verbose:\n","            self._save_print(progress, rob_acc, l2, elapsed_time, end='\\n')\n","\n","        if save_path is not None:\n","            x = torch.cat(image_list, 0)\n","            y = torch.cat(label_list, 0)\n","            torch.save((x, y), save_path)\n","            print('- Save complete!')\n","\n","        if given_training:\n","            self.model.train()\n","\n","        if return_verbose:\n","            return rob_acc, l2, elapsed_time\n","\n","    def _save_print(self, progress, rob_acc, l2, elapsed_time, end):\n","        print('- Save progress: %2.2f %% / Robust accuracy: %2.2f %% / L2: %1.5f (%2.3f it/s) \\t' \\\n","              % (progress, rob_acc, l2, elapsed_time), end=end)\n","\n","    def _get_target_label(self, images, labels=None):\n","        r\"\"\"\n","        Function for changing the attack mode.\n","        Return input labels.\n","        \"\"\"\n","        if self._target_map_function:\n","            return self._target_map_function(images, labels)\n","        raise ValueError('Please define target_map_function.')\n","\n","    def _get_least_likely_label(self, images, labels=None):\n","        r\"\"\"\n","        Function for changing the attack mode.\n","        Return least likely labels.\n","        \"\"\"\n","        outputs = self.model(images)\n","        if self._kth_min < 0:\n","            pos = outputs.shape[1] + self._kth_min + 1\n","        else:\n","            pos = self._kth_min\n","        _, target_labels = torch.kthvalue(outputs.data, pos)\n","        target_labels = target_labels.detach()\n","        return target_labels.long().to(self.device)\n","\n","    def _get_random_target_label(self, images, labels=None):\n","        if self._n_classses is None:\n","            outputs = self.model(images)\n","            if labels is None:\n","                _, labels = torch.max(outputs, dim=1)\n","            n_classses = outputs.shape[-1]\n","        else:\n","            n_classses = self._n_classses\n","\n","        target_labels = torch.zeros_like(labels)\n","        for counter in range(labels.shape[0]):\n","            l = list(range(n_classses))\n","            l.remove(labels[counter])\n","            t = self.random_int(0, len(l))\n","            target_labels[counter] = l[t]\n","\n","        return target_labels.long().to(self.device)\n","    \n","    def random_int(self, low=0, high=1, shape=[1]):\n","        t = low + (high - low) * torch.rand(shape).to(self.device)\n","        return t.long()\n","\n","    def _to_uint(self, images):\n","        r\"\"\"\n","        Function for changing the return type.\n","        Return images as int.\n","        \"\"\"\n","        return (images*255).type(torch.uint8)\n","\n","    def __str__(self):\n","        info = self.__dict__.copy()\n","\n","        del_keys = ['model', 'attack']\n","\n","        for key in info.keys():\n","            if key[0] == \"_\":\n","                del_keys.append(key)\n","\n","        for key in del_keys:\n","            del info[key]\n","\n","        info['attack_mode'] = self._attack_mode\n","        info['return_type'] = self._return_type\n","\n","        return self.attack + \"(\" + ', '.join('{}={}'.format(key, val) for key, val in info.items()) + \")\"\n","\n","    def __call__(self, *input, **kwargs):\n","        given_training = self.model.training\n","\n","        if self._model_training:\n","            self.model.train()\n","            for _, m in self.model.named_modules():\n","                if not self._batchnorm_training:\n","                    if 'BatchNorm' in m.__class__.__name__:\n","                        m = m.eval()\n","                if not self._dropout_training:\n","                    if 'Dropout' in m.__class__.__name__:\n","                        m = m.eval()\n","\n","        else:\n","            self.model.eval()\n","\n","        images = self.forward(*input, **kwargs)\n","\n","        if given_training:\n","            self.model.train()\n","\n","        if self._return_type == 'int':\n","            images = self._to_uint(images)\n","\n","        return images\n","\n","class SinglePGD(SingleAttack):\n","    r\"\"\"\n","    PGD in the paper 'Towards Deep Learning Models Resistant to Adversarial Attacks'\n","    [https://arxiv.org/abs/1706.06083]\n","\n","    Distance Measure : Linf\n","\n","    Arguments:\n","        model (nn.Module): model to attack.\n","        eps (float): maximum perturbation. (Default: 0.3)\n","        alpha (float): step size. (Default: 2/255)\n","        steps (int): number of steps. (Default: 40)\n","        random_start (bool): using random initialization of delta. (Default: True)\n","\n","    Shape:\n","        - images: :math:`(N, C, H, W)` where `N = number of batches`, `C = number of channels`,        `H = height` and `W = width`. It must have a range [0, 1].\n","        - labels: :math:`(N)` where each value :math:`y_i` is :math:`0 \\leq y_i \\leq` `number of labels`.\n","        - output: :math:`(N, C, H, W)`.\n","\n","    Examples::\n","        >>> attack = torchattacks.PGD(model, eps=8/255, alpha=1/255, steps=40, random_start=True)\n","        >>> adv_images = attack(images, labels)\n","\n","    \"\"\"\n","    def __init__(\n","        self,\n","        model,\n","        eps=0.3,\n","        alpha=2/255,\n","        steps=40,\n","        random_start=True,\n","    ):\n","        super().__init__(\"PGD\", model)\n","        self.eps = eps\n","        self.alpha = alpha\n","        self.steps = steps\n","        self.random_start = random_start\n","        self._supported_mode = ['default', 'targeted']\n","\n","    def forward(self, images, labels):\n","        r\"\"\"\n","        Overridden.\n","        \"\"\"\n","        images = images.clone().detach().to(self.device)\n","        labels = labels.clone().detach().to(self.device)\n","\n","        if self._targeted:\n","            target_labels = self._get_target_label(images, labels)\n","\n","        # loss1 = nn.CrossEntropyLoss()\n","        loss = nn.BCEWithLogitsLoss()\n","\n","        adv_images = images.clone().detach()\n","\n","        if self.random_start:\n","            # Starting at a uniformly random point\n","            adv_images = adv_images + torch.empty_like(adv_images).uniform_(-self.eps, self.eps)\n","            adv_images = torch.clamp(adv_images, min=0, max=1).detach()\n","\n","        for _ in range(self.steps):\n","            adv_images.requires_grad = True\n","            outputs = self.model(adv_images)\n","\n","            # Calculate loss\n","            if self._targeted:\n","                cost = -loss(outputs, target_labels)\n","            else:\n","                cost = loss(outputs, labels)\n","\n","            print(f\"Single Attack on SubNet Cost: {cost}\")\n","\n","            # Update adversarial images\n","            grad = torch.autograd.grad(cost, adv_images,\n","                                       retain_graph=False, create_graph=False)[0]\n","\n","            adv_images = adv_images.detach() + self.alpha*grad.sign()\n","            delta = torch.clamp(adv_images - images, min=-self.eps, max=self.eps)\n","            adv_images = torch.clamp(images + delta, min=0, max=1).detach()\n","\n","        return adv_images"],"execution_count":228,"outputs":[]},{"cell_type":"code","metadata":{"id":"jpMLaRseT1Jq","executionInfo":{"status":"ok","timestamp":1638558445008,"user_tz":300,"elapsed":182,"user":{"displayName":"Ameya Mahabaleshwarkar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWewArOnbcuIhn0zZGYi8CvzAMIgNfJVVvaTwTFg=s64","userId":"00795415078516995824"}}},"source":["combined_attack = PGDCombined(resnet_model.to('cpu'), subnet_model.to('cpu'), eps=8/255, alpha=8/(255*10), steps=100)\n","# combined_attack = SinglePGD(subnet_model.to('cpu'), eps=4/255, alpha=4/(255*40), steps=100)"],"execution_count":232,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oQUWm0bHVAv5","executionInfo":{"status":"ok","timestamp":1638558459341,"user_tz":300,"elapsed":13758,"user":{"displayName":"Ameya Mahabaleshwarkar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWewArOnbcuIhn0zZGYi8CvzAMIgNfJVVvaTwTFg=s64","userId":"00795415078516995824"}},"outputId":"f425932e-ce1e-4d56-ff16-5608b73cc5a3"},"source":["adv_inputs = combined_attack(\n","    torch.from_numpy(x_test[:10]).permute(0, 3, 1, 2),\n","    torch.from_numpy(y_test[:10])\n",")"],"execution_count":233,"outputs":[{"output_type":"stream","name":"stdout","text":["cost: 0.5153104066848755 | base classifier loss: 0.03767472505569458 | subnet loss: 0.4776357114315033\n","cost: 0.550883948802948 | base classifier loss: 0.0731065571308136 | subnet loss: 0.4777773916721344\n","cost: 0.6176415681838989 | base classifier loss: 0.13970905542373657 | subnet loss: 0.47793254256248474\n","cost: 0.7362610697746277 | base classifier loss: 0.2581440806388855 | subnet loss: 0.4781169891357422\n","cost: 0.9072962999343872 | base classifier loss: 0.4289325177669525 | subnet loss: 0.4783638119697571\n","cost: 1.1168028116226196 | base classifier loss: 0.6381542682647705 | subnet loss: 0.4786485731601715\n","cost: 1.337699055671692 | base classifier loss: 0.8587648272514343 | subnet loss: 0.47893422842025757\n","cost: 1.5390058755874634 | base classifier loss: 1.0598077774047852 | subnet loss: 0.47919806838035583\n","cost: 1.7103347778320312 | base classifier loss: 1.2308595180511475 | subnet loss: 0.47947531938552856\n","cost: 1.841158151626587 | base classifier loss: 1.361417531967163 | subnet loss: 0.47974056005477905\n","cost: 1.938979983329773 | base classifier loss: 1.4589712619781494 | subnet loss: 0.4800087511539459\n","cost: 1.9503395557403564 | base classifier loss: 1.4703130722045898 | subnet loss: 0.4800264239311218\n","cost: 1.9571467638015747 | base classifier loss: 1.4771173000335693 | subnet loss: 0.48002949357032776\n","cost: 1.962632656097412 | base classifier loss: 1.482602834701538 | subnet loss: 0.48002976179122925\n","cost: 1.9659955501556396 | base classifier loss: 1.4859546422958374 | subnet loss: 0.480040967464447\n","cost: 1.9696056842803955 | base classifier loss: 1.489569067955017 | subnet loss: 0.48003658652305603\n","cost: 1.972153663635254 | base classifier loss: 1.4921170473098755 | subnet loss: 0.4800366461277008\n","cost: 1.9743680953979492 | base classifier loss: 1.4943363666534424 | subnet loss: 0.4800317883491516\n","cost: 1.9761958122253418 | base classifier loss: 1.4961612224578857 | subnet loss: 0.48003464937210083\n","cost: 1.9775729179382324 | base classifier loss: 1.4975417852401733 | subnet loss: 0.4800311028957367\n","cost: 1.9782402515411377 | base classifier loss: 1.4982030391693115 | subnet loss: 0.48003721237182617\n","cost: 1.9786722660064697 | base classifier loss: 1.4986357688903809 | subnet loss: 0.4800364375114441\n","cost: 1.9789870977401733 | base classifier loss: 1.498944878578186 | subnet loss: 0.4800422191619873\n","cost: 1.9792845249176025 | base classifier loss: 1.4992456436157227 | subnet loss: 0.48003894090652466\n","cost: 1.9794976711273193 | base classifier loss: 1.4994513988494873 | subnet loss: 0.4800463318824768\n","cost: 1.9798657894134521 | base classifier loss: 1.4998247623443604 | subnet loss: 0.4800410866737366\n","cost: 1.9800399541854858 | base classifier loss: 1.499993920326233 | subnet loss: 0.48004603385925293\n","cost: 1.979623556137085 | base classifier loss: 1.4995805025100708 | subnet loss: 0.4800430238246918\n","cost: 1.9801663160324097 | base classifier loss: 1.5001163482666016 | subnet loss: 0.4800499975681305\n","cost: 1.9797546863555908 | base classifier loss: 1.4997098445892334 | subnet loss: 0.4800448417663574\n","cost: 1.9802024364471436 | base classifier loss: 1.5001509189605713 | subnet loss: 0.48005151748657227\n","cost: 1.9801514148712158 | base classifier loss: 1.5001065731048584 | subnet loss: 0.48004478216171265\n","cost: 1.9799540042877197 | base classifier loss: 1.4999017715454102 | subnet loss: 0.4800521731376648\n","cost: 1.9801883697509766 | base classifier loss: 1.5001415014266968 | subnet loss: 0.48004692792892456\n","cost: 1.9799844026565552 | base classifier loss: 1.49993097782135 | subnet loss: 0.4800534248352051\n","cost: 1.9801679849624634 | base classifier loss: 1.5001208782196045 | subnet loss: 0.4800471365451813\n","cost: 1.979966402053833 | base classifier loss: 1.4999138116836548 | subnet loss: 0.48005253076553345\n","cost: 1.980200171470642 | base classifier loss: 1.500152587890625 | subnet loss: 0.4800475537776947\n","cost: 1.9799920320510864 | base classifier loss: 1.499938726425171 | subnet loss: 0.48005327582359314\n","cost: 1.9801779985427856 | base classifier loss: 1.5001300573349 | subnet loss: 0.48004794120788574\n","cost: 1.9800443649291992 | base classifier loss: 1.499990701675415 | subnet loss: 0.48005372285842896\n","cost: 1.9801809787750244 | base classifier loss: 1.5001327991485596 | subnet loss: 0.48004817962646484\n","cost: 1.9800195693969727 | base classifier loss: 1.499966025352478 | subnet loss: 0.48005348443984985\n","cost: 1.9801816940307617 | base classifier loss: 1.5001335144042969 | subnet loss: 0.4800482392311096\n","cost: 1.9800204038619995 | base classifier loss: 1.4999668598175049 | subnet loss: 0.480053573846817\n","cost: 1.9801818132400513 | base classifier loss: 1.5001335144042969 | subnet loss: 0.480048269033432\n","cost: 1.9800207614898682 | base classifier loss: 1.4999672174453735 | subnet loss: 0.480053573846817\n","cost: 1.9801820516586304 | base classifier loss: 1.500133752822876 | subnet loss: 0.480048269033432\n","cost: 1.9800207614898682 | base classifier loss: 1.499967336654663 | subnet loss: 0.4800533652305603\n","cost: 1.9801819324493408 | base classifier loss: 1.5001335144042969 | subnet loss: 0.4800484776496887\n","cost: 1.9800217151641846 | base classifier loss: 1.4999672174453735 | subnet loss: 0.48005446791648865\n","cost: 1.98018217086792 | base classifier loss: 1.500133752822876 | subnet loss: 0.48004835844039917\n","cost: 1.9800208806991577 | base classifier loss: 1.499967336654663 | subnet loss: 0.480053573846817\n","cost: 1.9801820516586304 | base classifier loss: 1.500133752822876 | subnet loss: 0.480048269033432\n","cost: 1.9800207614898682 | base classifier loss: 1.499967336654663 | subnet loss: 0.4800533652305603\n","cost: 1.9801819324493408 | base classifier loss: 1.5001335144042969 | subnet loss: 0.4800484776496887\n","cost: 1.9800217151641846 | base classifier loss: 1.4999672174453735 | subnet loss: 0.48005446791648865\n","cost: 1.98018217086792 | base classifier loss: 1.500133752822876 | subnet loss: 0.48004835844039917\n","cost: 1.9800208806991577 | base classifier loss: 1.499967336654663 | subnet loss: 0.480053573846817\n","cost: 1.9801820516586304 | base classifier loss: 1.500133752822876 | subnet loss: 0.480048269033432\n","cost: 1.9800207614898682 | base classifier loss: 1.499967336654663 | subnet loss: 0.4800533652305603\n","cost: 1.9801819324493408 | base classifier loss: 1.5001335144042969 | subnet loss: 0.4800484776496887\n","cost: 1.9800217151641846 | base classifier loss: 1.4999672174453735 | subnet loss: 0.48005446791648865\n","cost: 1.98018217086792 | base classifier loss: 1.500133752822876 | subnet loss: 0.48004835844039917\n","cost: 1.9800208806991577 | base classifier loss: 1.499967336654663 | subnet loss: 0.480053573846817\n","cost: 1.9801820516586304 | base classifier loss: 1.500133752822876 | subnet loss: 0.480048269033432\n","cost: 1.9800207614898682 | base classifier loss: 1.499967336654663 | subnet loss: 0.4800533652305603\n","cost: 1.9801819324493408 | base classifier loss: 1.5001335144042969 | subnet loss: 0.4800484776496887\n","cost: 1.9800217151641846 | base classifier loss: 1.4999672174453735 | subnet loss: 0.48005446791648865\n","cost: 1.98018217086792 | base classifier loss: 1.500133752822876 | subnet loss: 0.48004835844039917\n","cost: 1.9800208806991577 | base classifier loss: 1.499967336654663 | subnet loss: 0.480053573846817\n","cost: 1.9801820516586304 | base classifier loss: 1.500133752822876 | subnet loss: 0.480048269033432\n","cost: 1.9800207614898682 | base classifier loss: 1.499967336654663 | subnet loss: 0.4800533652305603\n","cost: 1.9801819324493408 | base classifier loss: 1.5001335144042969 | subnet loss: 0.4800484776496887\n","cost: 1.9800217151641846 | base classifier loss: 1.4999672174453735 | subnet loss: 0.48005446791648865\n","cost: 1.98018217086792 | base classifier loss: 1.500133752822876 | subnet loss: 0.48004835844039917\n","cost: 1.9800208806991577 | base classifier loss: 1.499967336654663 | subnet loss: 0.480053573846817\n","cost: 1.9801820516586304 | base classifier loss: 1.500133752822876 | subnet loss: 0.480048269033432\n","cost: 1.9800207614898682 | base classifier loss: 1.499967336654663 | subnet loss: 0.4800533652305603\n","cost: 1.9801819324493408 | base classifier loss: 1.5001335144042969 | subnet loss: 0.4800484776496887\n","cost: 1.9800217151641846 | base classifier loss: 1.4999672174453735 | subnet loss: 0.48005446791648865\n","cost: 1.98018217086792 | base classifier loss: 1.500133752822876 | subnet loss: 0.48004835844039917\n","cost: 1.9800208806991577 | base classifier loss: 1.499967336654663 | subnet loss: 0.480053573846817\n","cost: 1.9801820516586304 | base classifier loss: 1.500133752822876 | subnet loss: 0.480048269033432\n","cost: 1.9800207614898682 | base classifier loss: 1.499967336654663 | subnet loss: 0.4800533652305603\n","cost: 1.9801819324493408 | base classifier loss: 1.5001335144042969 | subnet loss: 0.4800484776496887\n","cost: 1.9800217151641846 | base classifier loss: 1.4999672174453735 | subnet loss: 0.48005446791648865\n","cost: 1.98018217086792 | base classifier loss: 1.500133752822876 | subnet loss: 0.48004835844039917\n","cost: 1.9800208806991577 | base classifier loss: 1.499967336654663 | subnet loss: 0.480053573846817\n","cost: 1.9801820516586304 | base classifier loss: 1.500133752822876 | subnet loss: 0.480048269033432\n","cost: 1.9800207614898682 | base classifier loss: 1.499967336654663 | subnet loss: 0.4800533652305603\n","cost: 1.9801819324493408 | base classifier loss: 1.5001335144042969 | subnet loss: 0.4800484776496887\n","cost: 1.9800217151641846 | base classifier loss: 1.4999672174453735 | subnet loss: 0.48005446791648865\n","cost: 1.98018217086792 | base classifier loss: 1.500133752822876 | subnet loss: 0.48004835844039917\n","cost: 1.9800208806991577 | base classifier loss: 1.499967336654663 | subnet loss: 0.480053573846817\n","cost: 1.9801820516586304 | base classifier loss: 1.500133752822876 | subnet loss: 0.480048269033432\n","cost: 1.9800207614898682 | base classifier loss: 1.499967336654663 | subnet loss: 0.4800533652305603\n","cost: 1.9801819324493408 | base classifier loss: 1.5001335144042969 | subnet loss: 0.4800484776496887\n","cost: 1.9800217151641846 | base classifier loss: 1.4999672174453735 | subnet loss: 0.48005446791648865\n","cost: 1.98018217086792 | base classifier loss: 1.500133752822876 | subnet loss: 0.48004835844039917\n"]}]},{"cell_type":"code","metadata":{"id":"WoTEKzdbVKrb","executionInfo":{"status":"aborted","timestamp":1638558412119,"user_tz":300,"elapsed":8,"user":{"displayName":"Ameya Mahabaleshwarkar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWewArOnbcuIhn0zZGYi8CvzAMIgNfJVVvaTwTFg=s64","userId":"00795415078516995824"}}},"source":["adv_inputs.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JJvJdTLkXUUr"},"source":["# plt.imshow(adv_inputs[0].squeeze(0))\n","plt.imshow(adv_inputs[0].permute(1, 2, 0))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6keZxGB5i-C8"},"source":["plt.imshow(x_test[0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dvLGTFISjA0P","executionInfo":{"status":"ok","timestamp":1638556763868,"user_tz":300,"elapsed":190,"user":{"displayName":"Ameya Mahabaleshwarkar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWewArOnbcuIhn0zZGYi8CvzAMIgNfJVVvaTwTFg=s64","userId":"00795415078516995824"}},"outputId":"9b8f2c28-dac3-466a-97ef-ad8ea7314611"},"source":["torch.argmax(resnet_model(adv_inputs[0].unsqueeze(0).float()))"],"execution_count":134,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(5)"]},"metadata":{},"execution_count":134}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E28iGQz0j2by","executionInfo":{"status":"ok","timestamp":1638556765187,"user_tz":300,"elapsed":202,"user":{"displayName":"Ameya Mahabaleshwarkar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWewArOnbcuIhn0zZGYi8CvzAMIgNfJVVvaTwTFg=s64","userId":"00795415078516995824"}},"outputId":"7712c631-9077-4d1b-d100-b37f02fca6d2"},"source":["torch.argmax(resnet_model(torch.from_numpy(x_test[0]).permute(2, 0, 1).unsqueeze(0).float()))"],"execution_count":135,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(3)"]},"metadata":{},"execution_count":135}]},{"cell_type":"code","metadata":{"id":"3qq6ZQ9fXdlN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638556912259,"user_tz":300,"elapsed":168,"user":{"displayName":"Ameya Mahabaleshwarkar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWewArOnbcuIhn0zZGYi8CvzAMIgNfJVVvaTwTFg=s64","userId":"00795415078516995824"}},"outputId":"1d8e7643-f7ad-4ffe-8d28-55ac13b4fb57"},"source":["subnet_model(resnet_model(adv_inputs[1].unsqueeze(0).float(), return_interm_layer=2))"],"execution_count":147,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.4482]], grad_fn=<SigmoidBackward0>)"]},"metadata":{},"execution_count":147}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qkjA5HRKTQMH","executionInfo":{"status":"ok","timestamp":1638556832965,"user_tz":300,"elapsed":171,"user":{"displayName":"Ameya Mahabaleshwarkar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWewArOnbcuIhn0zZGYi8CvzAMIgNfJVVvaTwTFg=s64","userId":"00795415078516995824"}},"outputId":"09eb8200-0e65-4d81-f7aa-ef85c8813264"},"source":["subnet_model(resnet_model(torch.from_numpy(x_test[1]).permute(2, 0, 1).unsqueeze(0).float(), return_interm_layer=2))"],"execution_count":140,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.4460]], grad_fn=<SigmoidBackward0>)"]},"metadata":{},"execution_count":140}]}]}