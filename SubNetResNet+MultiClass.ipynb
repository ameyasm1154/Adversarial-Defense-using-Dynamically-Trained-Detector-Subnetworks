{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SubNetResNet+MultiClass.ipynb","provenance":[{"file_id":"188cxWuwSZXX1z9EQoURDb31fk-HkMS70","timestamp":1637799083514}],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyPMzzKBTWMFdT4lcRgUVgU6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"9XE_EIidCkFC"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wjMguj11-COv","executionInfo":{"status":"ok","timestamp":1638065839039,"user_tz":300,"elapsed":1339,"user":{"displayName":"Ameya Mahabaleshwarkar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWewArOnbcuIhn0zZGYi8CvzAMIgNfJVVvaTwTFg=s64","userId":"00795415078516995824"}}},"source":["import gc\n","import os\n","import sys\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import torchvision\n","\n","from PIL import Image\n","from torch.utils.data import DataLoader, Dataset\n","from torch.hub import load_state_dict_from_url\n","from torchvision import datasets, models, transforms\n","from torch.optim.lr_scheduler import ReduceLROnPlateau, ExponentialLR\n","from tqdm import tqdm\n","\n","from sklearn.metrics import accuracy_score, f1_score\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.nn.init as init\n","\n","from torch.autograd import Variable"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"YSNW4FaOb4Na","executionInfo":{"status":"ok","timestamp":1638065839042,"user_tz":300,"elapsed":15,"user":{"displayName":"Ameya Mahabaleshwarkar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWewArOnbcuIhn0zZGYi8CvzAMIgNfJVVvaTwTFg=s64","userId":"00795415078516995824"}}},"source":["N_ATTACKS = 3\n","N_SUBNET_LABELS = N_ATTACKS # + 1 # add label for non-adversarial"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"F7TjhtIZ-HOh","executionInfo":{"status":"ok","timestamp":1638066511328,"user_tz":300,"elapsed":333,"user":{"displayName":"Ameya Mahabaleshwarkar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWewArOnbcuIhn0zZGYi8CvzAMIgNfJVVvaTwTFg=s64","userId":"00795415078516995824"}}},"source":["def _weights_init(m):\n","    classname = m.__class__.__name__\n","    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n","        init.kaiming_normal_(m.weight)\n","\n","class LambdaLayer(nn.Module):\n","    def __init__(self, lambd):\n","      super(LambdaLayer, self).__init__()\n","      self.lambd = lambd\n","\n","    def forward(self, x):\n","      return self.lambd(x)\n","\n","class BasicBlock(nn.Module):\n","    expansion = 1\n","\n","    def __init__(self, in_planes, planes, stride=1, option='A'):\n","        super(BasicBlock, self).__init__()\n","        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != planes:\n","            if option == 'A':\n","                \"\"\"\n","                For CIFAR10 ResNet paper uses option A.\n","                \"\"\"\n","                self.shortcut = LambdaLayer(lambda x:\n","                                            F.pad(x[:, :, ::2, ::2], (0, 0, 0, 0, planes//4, planes//4), \"constant\", 0))\n","            elif option == 'B':\n","                self.shortcut = nn.Sequential(\n","                     nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n","                     nn.BatchNorm2d(self.expansion * planes)\n","                )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.bn2(self.conv2(out))\n","        out += self.shortcut(x)\n","        out = F.relu(out)\n","        return out\n","\n","\n","class ResNet(nn.Module):\n","    def __init__(self, block, num_blocks, num_classes=10):\n","        super(ResNet, self).__init__()\n","        self.in_planes = 16\n","\n","        self.in_channels = 1 # 3 for CIFAR OR 1 for MNIST\n","        self.conv1 = nn.Conv2d(self.in_channels, 16, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(16)\n","        self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1)\n","        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n","        self.layer3 = self._make_layer(block, 64, num_blocks[2], stride=2)\n","        self.linear = nn.Linear(64, num_classes)\n","\n","        self.apply(self._weights_init)\n","\n","    def _weights_init(self, m):\n","        classname = m.__class__.__name__\n","        if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n","          nn.init.kaiming_normal_(m.weight)\n","    \n","    def _make_layer(self, block, planes, num_blocks, stride):\n","        strides = [stride] + [1]*(num_blocks-1)\n","        layers = []\n","        for stride in strides:\n","            layers.append(block(self.in_planes, planes, stride))\n","            self.in_planes = planes * block.expansion\n","\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x, return_interm_layer=None):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.layer1(out)\n","        if return_interm_layer == 1:\n","            return out\n","        out = self.layer2(out)\n","        if return_interm_layer == 2:\n","            return out\n","        out = self.layer3(out)\n","        if return_interm_layer == 3:\n","            return out\n","        out = F.avg_pool2d(out, out.size()[3])\n","        print('embed = ', out.shape)\n","        out = out.view(out.size(0), -1)\n","        if return_interm_layer == -1:\n","            # print('embed = ', out.shape)\n","            return out\n","        out = self.linear(out)\n","        \n","        return out\n","\n","def resnet20():\n","    return ResNet(BasicBlock, [3, 3, 3])\n","\n","def resnet32():\n","    return ResNet(BasicBlock, [5, 5, 5])\n","\n","def resnet44():\n","    return ResNet(BasicBlock, [7, 7, 7])\n","\n","def resnet56():\n","    return ResNet(BasicBlock, [9, 9, 9])\n","\n","def resnet110():\n","    return ResNet(BasicBlock, [18, 18, 18])\n","\n","def resnet1202():\n","    return ResNet(BasicBlock, [200, 200, 200])"],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"id":"BICuX46P-aZC","executionInfo":{"status":"ok","timestamp":1638066512429,"user_tz":300,"elapsed":199,"user":{"displayName":"Ameya Mahabaleshwarkar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWewArOnbcuIhn0zZGYi8CvzAMIgNfJVVvaTwTFg=s64","userId":"00795415078516995824"}}},"source":["class MultiClassSubNet(nn.Module):\n","    def __init__(self, in_channels):\n","        super(MultiClassSubNet, self).__init__()\n","        conv1 = nn.Conv2d(in_channels, 64, kernel_size=2, stride=2, padding=0, bias=False)\n","        bn1 = nn.BatchNorm2d(64)\n","        conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=0, bias=False)\n","        bn2 = nn.BatchNorm2d(128)\n","        conv3 = nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=0, bias=False)\n","        bn3 = nn.BatchNorm2d(256)\n","        relu = nn.ReLU(inplace=True)\n","        flatten = nn.Flatten()\n","        linear = nn.Linear(256, N_SUBNET_LABELS)\n","\n","        self.layers = nn.Sequential(\n","            conv1,\n","            bn1,\n","            relu,\n","            conv2,\n","            bn2,\n","            relu,\n","            conv3,\n","            bn3,\n","            relu,\n","            flatten,\n","            linear,\n","        )\n","\n","        self.layers.apply(self.init_param)\n","\n","    def forward(self, x, return_embedding=False):\n","        embedding = None\n","        for itr, layer in enumerate(self.layers):\n","          x = layer(x)\n","          if return_embedding and itr == len(self.layers)-1:\n","            embedding = x\n","\n","        return x\n","\n","    def init_param(self, param):\n","        if type(param) in [nn.Linear, nn.Conv2d]:\n","            nn.init.kaiming_uniform_(param.weight)"],"execution_count":34,"outputs":[]},{"cell_type":"code","metadata":{"id":"fjqA1KiJ-hLC","executionInfo":{"status":"ok","timestamp":1638066513688,"user_tz":300,"elapsed":444,"user":{"displayName":"Ameya Mahabaleshwarkar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWewArOnbcuIhn0zZGYi8CvzAMIgNfJVVvaTwTFg=s64","userId":"00795415078516995824"}}},"source":["def train_subnet(\n","    resnet_model,\n","    interm_layer,\n","    subnet_model,\n","    subnet_optimizer,\n","    subnet_criterion,\n","    subnet_scheduler,\n","    # unattacked_train_data,\n","    # unattacked_test_data,\n","    attacked_train_data_list,\n","    attacked_test_data_list,\n","    device,\n","    epochs=100,\n","    batch_size=64,\n","):\n","    subnet_model.train()\n","    resnet_model.eval()\n","    batches = []\n","    embeddings = []\n","\n","    for epoch in range(epochs):\n","\n","      avg_loss = 0.0\n","      for batch_itr in tqdm(range(0, len(attacked_train_data_list[0]), batch_size)):\n","          \n","          all_attacked_input, all_attacked_labels = [], []\n","          for label_id, attacked_train_data in enumerate(attacked_train_data_list):\n","            attacked_input = attacked_train_data[batch_itr:batch_itr+batch_size]\n","            all_attacked_input.append(attacked_input)\n","            attacked_labels = torch.full((attacked_input.shape[0], 1), label_id, dtype=torch.float32)\n","            all_attacked_labels.append(attacked_labels)\n","\n","          input = torch.cat(all_attacked_input, axis=0)\n","          labels = torch.cat(all_attacked_labels, axis=0)\n","\n","          assert input.shape[0] == labels.shape[0]\n","          shuffle_indices = np.arange(input.shape[0])\n","          np.random.shuffle(shuffle_indices)\n","          input, labels = input[shuffle_indices].squeeze(0), labels[shuffle_indices].squeeze(0)\n","\n","          # unattacked_input = unattacked_train_data[batch_itr:batch_itr+batch_size]\n","          # unattacked_labels = torch.zeros((unattacked_input.shape[0], 1), dtype=torch.float32)\n","\n","          # input = torch.cat((unattacked_input, all_attacked_input), axis=0)\n","          # labels = torch.cat((unattacked_labels, all_attacked_labels), axis=0)\n","\n","          input, labels = input.to(device), labels.to(device)\n","\n","          with torch.no_grad():\n","            embeddings.append(resnet_model(input.float(), return_interm_layer=-1))\n","          input = resnet_model(input.float(), return_interm_layer=interm_layer)\n","          output = subnet_model(input)\n","\n","          loss = subnet_criterion(output.float(), labels.squeeze(1).long())\n","          # print(\"loss\", loss)\n","          loss.backward()\n","          avg_loss += loss.item()\n","\n","          subnet_optimizer.step()\n","\n","          del input\n","          del labels\n","          del loss\n","          torch.cuda.empty_cache()\n","\n","      val_loss, val_acc, val_f1, val_embeddings = test_subnet(\n","          resnet_model,\n","          interm_layer,\n","          subnet_model,\n","          subnet_criterion,\n","          # unattacked_test_data,\n","          attacked_test_data_list,\n","          device,\n","      )\n","\n","      print('Val Loss: {:.4f} | Val Acc {:.4f} | Val F1: {:.4f}'.format(val_loss, val_acc, val_f1))\n","      torch.save({\n","          'epoch': epoch,\n","          'model_state_dict': resnet_model.state_dict(),\n","          'optimizer_state_dict': subnet_optimizer.state_dict(),\n","      }, './' + str(epoch) + 'model.pt')\n","\n","      embeddings.extend(val_embeddings)\n","\n","      # subnet_scheduler.step(val_loss)\n","\n","    return torch.cat(embeddings, axis=0).detach().cpu().numpy()\n","\n","\n","def test_subnet(\n","    resnet_model,\n","    interm_layer,\n","    subnet_model,\n","    criterion,\n","    # unattacked_test_data,\n","    attacked_test_data_list,\n","    device,\n","    batch_size=64,\n","):\n","    resnet_model.eval()\n","    subnet_model.eval()\n","    test_loss = []\n","    accuracies, f1_scores = [], []\n","    embeddings = []\n","\n","    for batch_itr in tqdm(range(0, len(attacked_test_data_list[0]), batch_size)):\n","        all_attacked_input, all_attacked_labels = [], []\n","        for label_id, attacked_test_data in enumerate(attacked_test_data_list):\n","          attacked_input = attacked_test_data[batch_itr:batch_itr+batch_size]\n","          all_attacked_input.append(attacked_input)\n","\n","          attacked_labels = torch.full((attacked_input.shape[0], 1), label_id, dtype=torch.float32)\n","          all_attacked_labels.append(attacked_labels)\n","\n","        input = torch.cat(all_attacked_input, axis=0)\n","        labels = torch.cat(all_attacked_labels, axis=0)\n","\n","        assert input.shape[0] == labels.shape[0]\n","        shuffle_indices = np.arange(input.shape[0])\n","        np.random.shuffle(shuffle_indices)\n","        input, labels = input[shuffle_indices].squeeze(0), labels[shuffle_indices].squeeze(0)\n","        \n","        # unattacked_input = unattacked_test_data[batch_itr:batch_itr+batch_size]\n","        # unattacked_labels = torch.zeros((unattacked_input.shape[0], 1), dtype=torch.float32)\n","\n","        # input = torch.cat((unattacked_input, all_attacked_input), axis=0)\n","        # labels = torch.cat((unattacked_labels, all_attacked_labels), axis=0)\n","\n","        input, labels = input.to(device), labels.to(device)\n","\n","        with torch.no_grad():\n","            embeddings.append(resnet_model(input.float(), return_interm_layer=-1))\n","            input = resnet_model(input.float(), return_interm_layer=interm_layer)\n","            output = subnet_model(input)\n","            # output = torch.argmax(output, axis=1).unsqueeze(1)\n","\n","        pred_labels = torch.argmax(output, axis=1).float()\n","        loss = criterion(output.float(), labels.squeeze(1).long())\n","\n","        # print(pred_labels.flatten().cpu().shape)\n","        # print(labels.flatten().cpu().shape)\n","        accuracy = accuracy_score(pred_labels.flatten().cpu(), labels.flatten().cpu())\n","        accuracies.append(accuracy)\n","        f1 = f1_score(pred_labels.flatten().cpu(), labels.flatten().cpu(), average=None)\n","        f1_scores.append(f1)\n","        test_loss.extend([loss.item()]*input.size()[0])\n","        \n","        del input\n","        del labels\n","        del loss\n","        torch.cuda.empty_cache()\n","\n","    subnet_model.train()\n","\n","    return np.mean(test_loss), np.mean(accuracies), np.mean(f1_scores), embeddings"],"execution_count":35,"outputs":[]},{"cell_type":"code","metadata":{"id":"KSleqNm_w5CA","executionInfo":{"status":"ok","timestamp":1638066514721,"user_tz":300,"elapsed":168,"user":{"displayName":"Ameya Mahabaleshwarkar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWewArOnbcuIhn0zZGYi8CvzAMIgNfJVVvaTwTFg=s64","userId":"00795415078516995824"}}},"source":["def Normalize0to1(AA):\n","    AA[:, :, :, 0] -= AA[:, :, :, 0].min().item()\n","    AA[:, :, :, 0] /= AA[:, :, :, 0].max().item()\n","\n","    AA[:, :, :, 1] -= AA[:, :, :, 1].min().item()\n","    AA[:, :, :, 1] /= AA[:, :, :, 1].max().item()\n","\n","    AA[:, :, :, 2] -= AA[:, :, :, 2].min().item()\n","    AA[:, :, :, 2] /= AA[:, :, :, 2].max().item()\n","\n","    return AA / 225."],"execution_count":36,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z8A0XrFTo0zP","executionInfo":{"status":"ok","timestamp":1638066515526,"user_tz":300,"elapsed":220,"user":{"displayName":"Ameya Mahabaleshwarkar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWewArOnbcuIhn0zZGYi8CvzAMIgNfJVVvaTwTFg=s64","userId":"00795415078516995824"}},"outputId":"c72a371d-b1fe-4938-a7a6-e35d374187a3"},"source":["!ls '/content/drive/MyDrive/11785 - Project/data'"],"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["benign_cifar.npy\t      pgd_cifar_default_art.npy\n","benign_mnist.npy\t      pgd_cifar_default_torchattacks_new.npy\n","cwlinf_cifar_default_art.npy  pgd_cifar_eps0.1_torchattacks.npy\n","cwlinf_mnist_default_art.npy  pgd_cifar_eps0.3_alpha0.1_steps7.npy\n","fgsm_cifar_default_art.npy    pgd_mnist_default_art.npy\n","fgsm_mnist_eps0.5.npy\t      pgd_mnist_eps0.3_alpha0.1_steps7.npy\n"]}]},{"cell_type":"code","metadata":{"id":"XMnBGC9TGQFI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638066516579,"user_tz":300,"elapsed":390,"user":{"displayName":"Ameya Mahabaleshwarkar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWewArOnbcuIhn0zZGYi8CvzAMIgNfJVVvaTwTFg=s64","userId":"00795415078516995824"}},"outputId":"e0d0e3c4-4ecf-4725-abdd-db20738bbd90"},"source":["batch_size = 64\n","\n","# normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","\n","# unattacked_data_path = \"/content/drive/MyDrive/11785 - Project/data/benign_cifar.npy\"\n","unattacked_data_path = \"/content/drive/MyDrive/11785 - Project/data/benign_mnist.npy\"\n","unattacked_data = np.load(unattacked_data_path, allow_pickle=True).astype(float)\n","unattacked_data = torch.from_numpy(unattacked_data)\n","# unattacked_data = Normalize0to1(unattacked_data)\n","# unattacked_data = normalize(unattacked_data)\n","unattacked_train_data = unattacked_data[:9000]\n","unattacked_test_data = unattacked_data[9000:]\n","print(unattacked_data.shape)\n","\n","# attacked_data_path1 = \"/content/drive/MyDrive/11785 - Project/data/cwlinf_cifar_default_art.npy\"\n","attacked_data_path1 = \"/content/drive/MyDrive/11785 - Project/data/cwlinf_mnist_default_art.npy\"\n","attacked_data1 = np.load(attacked_data_path1, allow_pickle=True).astype(float)\n","attacked_data1 = torch.from_numpy(attacked_data1)\n","# attacked_data1 = Normalize0to1(attacked_data1)\n","# attacked_data1 = normalize(attacked_data1)\n","attacked_train_data1 = attacked_data1[:9000]\n","attacked_test_data1 = attacked_data1[9000:]\n","print(attacked_data1.shape)\n","\n","# attacked_data_path2 = \"/content/drive/MyDrive/11785 - Project/data/fgsm_cifar_default_art.npy\"\n","attacked_data_path2 = \"/content/drive/MyDrive/11785 - Project/data/fgsm_mnist_eps0.5.npy\"\n","attacked_data2 = np.load(attacked_data_path2, allow_pickle=True).astype(float)\n","attacked_data2 = torch.from_numpy(attacked_data2.transpose(1, 0, 2, 3))\n","# attacked_data2 = Normalize0to1(attacked_data2)\n","# attacked_data2 = normalize(attacked_data2)\n","attacked_train_data2 = attacked_data2[:9000]\n","attacked_test_data2 = attacked_data2[9000:]\n","print(attacked_data2.shape)\n","\n","# attacked_data_path3 = \"/content/drive/MyDrive/11785 - Project/data/pgd_cifar_default_art.npy\"\n","attacked_data_path3 = \"/content/drive/MyDrive/11785 - Project/data/pgd_mnist_default_art.npy\"\n","attacked_data3 = np.load(attacked_data_path3, allow_pickle=True).astype(float)\n","attacked_data3 = torch.from_numpy(attacked_data3)\n","# attacked_data3 = Normalize0to1(attacked_data3)\n","# attacked_data3 = normalize(attacked_data3)\n","attacked_train_data3 = attacked_data3[:9000]\n","attacked_test_data3 = attacked_data3[9000:]\n","print(attacked_data3.shape)\n","\n","attacked_train_data_list = [attacked_train_data1, attacked_train_data2, attacked_train_data3]\n","attacked_test_data_list = [attacked_test_data1, attacked_test_data2, attacked_test_data3]"],"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([10000, 1, 28, 28])\n","torch.Size([10000, 1, 28, 28])\n","torch.Size([10000, 1, 28, 28])\n","torch.Size([10000, 1, 28, 28])\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MeEKZ9l6qP7N","executionInfo":{"status":"ok","timestamp":1638066517666,"user_tz":300,"elapsed":337,"user":{"displayName":"Ameya Mahabaleshwarkar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWewArOnbcuIhn0zZGYi8CvzAMIgNfJVVvaTwTFg=s64","userId":"00795415078516995824"}},"outputId":"51aeaafe-eff8-46cc-e7da-901a0fc3c296"},"source":["! ls \"/content/drive/MyDrive/11785 - Project/\""],"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["AdversarialDetection.pdf  data\t\t      mnist_model.pth\n","cifar10_model.pth\t  Experiments.gsheet  Presentation.gslides\n"]}]},{"cell_type":"code","metadata":{"id":"mRiNlZue-kxG","executionInfo":{"status":"ok","timestamp":1638066518464,"user_tz":300,"elapsed":170,"user":{"displayName":"Ameya Mahabaleshwarkar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWewArOnbcuIhn0zZGYi8CvzAMIgNfJVVvaTwTFg=s64","userId":"00795415078516995824"}}},"source":["cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if cuda else \"cpu\")\n","\n","resnet_model = resnet32()\n","resnet_model.to(device)\n","# checkpoint = torch.load(\"/content/drive/MyDrive/11785 - Project/cifar10_model.pth\")\n","checkpoint = torch.load(\"/content/drive/MyDrive/11785 - Project/mnist_model.pth\")\n","# mod_checkpoint = {k.replace(\"module.\", \"\"): v for k, v in checkpoint['state_dict'].items()}\n","resnet_model.load_state_dict(checkpoint)\n","resnet_optimizer = torch.optim.SGD(resnet_model.parameters(), lr=0.1, weight_decay=5e-5, momentum=0.9)\n","resnet_criterion = nn.CrossEntropyLoss()\n","resnet_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(resnet_optimizer, T_0=10, T_mult=2, eta_min=0.01, last_epoch=-1)\n","\n","# output size at diff intermediate layers of resnet\n","interm_layer2dim = {1: 16, 2: 32, 3: 64}\n","interm_layer = 2\n","\n","subnet_model = MultiClassSubNet(interm_layer2dim[interm_layer])\n","subnet_model.to(device)\n","subnet_optimizer = torch.optim.Adam(subnet_model.parameters(), lr=0.0001, betas=(0.99, 0.999))\n","subnet_criterion = nn.CrossEntropyLoss()\n","subnet_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(subnet_optimizer, T_0=10, T_mult=2, eta_min=0.01, last_epoch=-1)"],"execution_count":40,"outputs":[]},{"cell_type":"code","metadata":{"id":"1Iq2wgAR-2Oj","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1638066530772,"user_tz":300,"elapsed":2242,"user":{"displayName":"Ameya Mahabaleshwarkar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWewArOnbcuIhn0zZGYi8CvzAMIgNfJVVvaTwTFg=s64","userId":"00795415078516995824"}},"outputId":"0918bb46-52e9-471d-f8e3-66cbd1219fe1"},"source":["embeddings = train_subnet(\n","  resnet_model,\n","  interm_layer,\n","  subnet_model,\n","  subnet_optimizer,\n","  subnet_criterion,\n","  subnet_scheduler,\n","  # unattacked_train_data,\n","  # unattacked_test_data,\n","  attacked_train_data_list,\n","  attacked_test_data_list,\n","  device,\n","  epochs=3,\n",")"],"execution_count":41,"outputs":[{"output_type":"stream","name":"stderr","text":["\r 91%|█████████ | 128/141 [00:09<00:00, 14.11it/s]"]},{"output_type":"stream","name":"stdout","text":["embed =  torch.Size([192, 64, 1, 1])\n","embed =  torch.Size([192, 64, 1, 1])\n","embed =  torch.Size([192, 64, 1, 1])\n"]},{"output_type":"stream","name":"stderr","text":[" 94%|█████████▎| 132/141 [00:09<00:00, 14.19it/s]"]},{"output_type":"stream","name":"stdout","text":["embed =  torch.Size([192, 64, 1, 1])\n","embed =  torch.Size([192, 64, 1, 1])\n","embed =  torch.Size([192, 64, 1, 1])\n"]},{"output_type":"stream","name":"stderr","text":["\r 95%|█████████▌| 134/141 [00:09<00:00, 14.07it/s]"]},{"output_type":"stream","name":"stdout","text":["embed =  torch.Size([192, 64, 1, 1])\n","embed =  torch.Size([192, 64, 1, 1])\n","embed =  torch.Size([192, 64, 1, 1])\n"]},{"output_type":"stream","name":"stderr","text":[" 98%|█████████▊| 138/141 [00:09<00:00, 14.12it/s]"]},{"output_type":"stream","name":"stdout","text":["embed =  torch.Size([192, 64, 1, 1])\n","embed =  torch.Size([192, 64, 1, 1])\n","embed =  torch.Size([192, 64, 1, 1])\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 141/141 [00:09<00:00, 14.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["embed =  torch.Size([192, 64, 1, 1])\n","embed =  torch.Size([192, 64, 1, 1])\n","embed =  torch.Size([120, 64, 1, 1])\n"]},{"output_type":"stream","name":"stderr","text":[" 31%|███▏      | 5/16 [00:00<00:00, 46.17it/s]"]},{"output_type":"stream","name":"stdout","text":["embed =  torch.Size([192, 64, 1, 1])\n","embed =  torch.Size([192, 64, 1, 1])\n","embed =  torch.Size([192, 64, 1, 1])\n","embed =  torch.Size([192, 64, 1, 1])\n","embed =  torch.Size([192, 64, 1, 1])\n","embed =  torch.Size([192, 64, 1, 1])\n","embed =  torch.Size([192, 64, 1, 1])\n","embed =  torch.Size([192, 64, 1, 1])\n","embed =  torch.Size([192, 64, 1, 1])\n","embed =  torch.Size([192, 64, 1, 1])\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 16/16 [00:00<00:00, 46.61it/s]\n"]},{"output_type":"stream","name":"stdout","text":["embed =  torch.Size([192, 64, 1, 1])\n","embed =  torch.Size([192, 64, 1, 1])\n","embed =  torch.Size([192, 64, 1, 1])\n","embed =  torch.Size([192, 64, 1, 1])\n","embed =  torch.Size([192, 64, 1, 1])\n","embed =  torch.Size([120, 64, 1, 1])\n","Val Loss: 0.1015 | Val Acc 0.9585 | Val F1: 0.9582\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/141 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["embed =  torch.Size([192, 64, 1, 1])\n"]},{"output_type":"stream","name":"stderr","text":["\r  1%|▏         | 2/141 [00:00<00:09, 13.99it/s]"]},{"output_type":"stream","name":"stdout","text":["embed =  torch.Size([192, 64, 1, 1])\n","embed =  torch.Size([192, 64, 1, 1])\n","embed =  torch.Size([192, 64, 1, 1])\n"]},{"output_type":"stream","name":"stderr","text":["\r  3%|▎         | 4/141 [00:00<00:09, 13.92it/s]"]},{"output_type":"stream","name":"stdout","text":["embed =  torch.Size([192, 64, 1, 1])\n","embed =  torch.Size([192, 64, 1, 1])\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 6/141 [00:00<00:09, 13.90it/s]"]},{"output_type":"stream","name":"stdout","text":["embed =  torch.Size([192, 64, 1, 1])\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 8/141 [00:00<00:09, 13.89it/s]"]},{"output_type":"stream","name":"stdout","text":["embed =  torch.Size([192, 64, 1, 1])\n","embed =  torch.Size([192, 64, 1, 1])\n","embed =  torch.Size([192, 64, 1, 1])\n"]},{"output_type":"stream","name":"stderr","text":["  8%|▊         | 11/141 [00:00<00:09, 13.78it/s]"]},{"output_type":"stream","name":"stdout","text":["embed =  torch.Size([192, 64, 1, 1])\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-41-f7b2371d3d89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mattacked_test_data_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m   \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m )\n","\u001b[0;32m<ipython-input-35-b2f38aee94ae>\u001b[0m in \u001b[0;36mtrain_subnet\u001b[0;34m(resnet_model, interm_layer, subnet_model, subnet_optimizer, subnet_criterion, subnet_scheduler, attacked_train_data_list, attacked_test_data_list, device, epochs, batch_size)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m           \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_interm_layer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m           \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresnet_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_interm_layer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterm_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m           \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubnet_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-33-41339ede3b79>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, return_interm_layer)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_interm_layer\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_interm_layer\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-33-41339ede3b79>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshortcut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SOMX6j7FMtMi","executionInfo":{"status":"ok","timestamp":1638065950870,"user_tz":300,"elapsed":262,"user":{"displayName":"Ameya Mahabaleshwarkar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWewArOnbcuIhn0zZGYi8CvzAMIgNfJVVvaTwTFg=s64","userId":"00795415078516995824"}},"outputId":"71e3e6e7-9fa7-4d47-8326-e790a5536ce7"},"source":["embeddings.shape"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(150000, 64)"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"z0WHlkseV1KQ"},"source":["from sklearn.manifold import TSNE\n","\n","X_embed\n"],"execution_count":null,"outputs":[]}]}