{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SubNetworkDynamicTraining.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyPBRYPbm6Tq+ozmdmKIYxj/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"Fw18xK0ANwvs"},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OAIckN--awoV"},"source":["! pip install torchattacks"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YrSp_qMjQzTI","executionInfo":{"status":"ok","timestamp":1638228819598,"user_tz":300,"elapsed":300,"user":{"displayName":"Ameya Mahabaleshwarkar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWewArOnbcuIhn0zZGYi8CvzAMIgNfJVVvaTwTFg=s64","userId":"00795415078516995824"}}},"source":["import gc\n","import os\n","import sys\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import torchattacks\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.nn.init as init\n","import torch.optim as optim\n","import torchvision\n","from torch.utils.data import DataLoader, Dataset\n","from torch.hub import load_state_dict_from_url\n","from torchvision import datasets, models, transforms\n","from torch.optim.lr_scheduler import ReduceLROnPlateau, ExponentialLR\n","from torch.autograd import Variable\n","\n","from PIL import Image\n","from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n","from tqdm.notebook import tqdm"],"execution_count":73,"outputs":[]},{"cell_type":"code","metadata":{"id":"2XiVxTXV1njm","executionInfo":{"status":"ok","timestamp":1638228819928,"user_tz":300,"elapsed":2,"user":{"displayName":"Ameya Mahabaleshwarkar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWewArOnbcuIhn0zZGYi8CvzAMIgNfJVVvaTwTFg=s64","userId":"00795415078516995824"}}},"source":["PGD_ATTACK_EPS = 2/255"],"execution_count":74,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bp4VA6sERZg3"},"source":["### Base Classifier - ResNet"]},{"cell_type":"code","metadata":{"id":"ssh9qP_dQ1yW","executionInfo":{"status":"ok","timestamp":1638228987075,"user_tz":300,"elapsed":268,"user":{"displayName":"Ameya Mahabaleshwarkar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWewArOnbcuIhn0zZGYi8CvzAMIgNfJVVvaTwTFg=s64","userId":"00795415078516995824"}}},"source":["def _weights_init(m):\n","    classname = m.__class__.__name__\n","    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n","        init.kaiming_normal_(m.weight)\n","\n","class LambdaLayer(nn.Module):\n","    def __init__(self, lambd):\n","      super(LambdaLayer, self).__init__()\n","      self.lambd = lambd\n","\n","    def forward(self, x):\n","      return self.lambd(x)\n","\n","class BasicBlock(nn.Module):\n","    expansion = 1\n","\n","    def __init__(self, in_planes, planes, stride=1, option='A'):\n","        super(BasicBlock, self).__init__()\n","        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != planes:\n","            if option == 'A':\n","                \"\"\"\n","                For CIFAR10 ResNet paper uses option A.\n","                \"\"\"\n","                self.shortcut = LambdaLayer(lambda x:\n","                                            F.pad(x[:, :, ::2, ::2], (0, 0, 0, 0, planes//4, planes//4), \"constant\", 0))\n","            elif option == 'B':\n","                self.shortcut = nn.Sequential(\n","                     nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n","                     nn.BatchNorm2d(self.expansion * planes)\n","                )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.bn2(self.conv2(out))\n","        out += self.shortcut(x)\n","        out = F.relu(out)\n","        return out\n","\n","\n","class ResNet(nn.Module):\n","    def __init__(self, block, num_blocks, num_classes=10):\n","        super(ResNet, self).__init__()\n","        self.in_planes = 16\n","\n","        self.in_channels = 3 # 3 for CIFAR OR 1 for MNIST\n","        self.conv1 = nn.Conv2d(self.in_channels, 16, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(16)\n","        self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1)\n","        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n","        self.layer3 = self._make_layer(block, 64, num_blocks[2], stride=2)\n","        self.linear = nn.Linear(64, num_classes)\n","\n","        self.apply(self._weights_init)\n","\n","    def _weights_init(self, m):\n","        classname = m.__class__.__name__\n","        if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n","          nn.init.kaiming_normal_(m.weight)\n","    \n","    def _make_layer(self, block, planes, num_blocks, stride):\n","        strides = [stride] + [1]*(num_blocks-1)\n","        layers = []\n","        for stride in strides:\n","            layers.append(block(self.in_planes, planes, stride))\n","            self.in_planes = planes * block.expansion\n","\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x, return_interm_layer=None):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.layer1(out)\n","        if return_interm_layer == 1:\n","            return out\n","        out = self.layer2(out)\n","        if return_interm_layer == 2:\n","            return out\n","        out = self.layer3(out)\n","        if return_interm_layer == 3:\n","            return out\n","        out = F.avg_pool2d(out, out.size()[3])\n","        out = out.view(out.size(0), -1)\n","        if return_interm_layer == -1:\n","            return out\n","        out = self.linear(out)\n","        \n","        return out\n","\n","def resnet20():\n","    return ResNet(BasicBlock, [3, 3, 3])\n","\n","def resnet32():\n","    return ResNet(BasicBlock, [5, 5, 5])\n","\n","def resnet44():\n","    return ResNet(BasicBlock, [7, 7, 7])\n","\n","def resnet56():\n","    return ResNet(BasicBlock, [9, 9, 9])\n","\n","def resnet110():\n","    return ResNet(BasicBlock, [18, 18, 18])\n","\n","def resnet1202():\n","    return ResNet(BasicBlock, [200, 200, 200])"],"execution_count":96,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t5M0vERxRd-N"},"source":["### SubNetwork"]},{"cell_type":"code","metadata":{"id":"E5jNIVmYRdfQ","executionInfo":{"status":"ok","timestamp":1638228987264,"user_tz":300,"elapsed":4,"user":{"displayName":"Ameya Mahabaleshwarkar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWewArOnbcuIhn0zZGYi8CvzAMIgNfJVVvaTwTFg=s64","userId":"00795415078516995824"}}},"source":["class SubNet(nn.Module):\n","    def __init__(self, in_channels):\n","        super(SubNet, self).__init__()\n","        conv1 = nn.Conv2d(in_channels, 96, kernel_size=3, stride=1, padding=0, bias=False)\n","        bn1 = nn.BatchNorm2d(96)\n","        conv2 = nn.Conv2d(96, 192, kernel_size=3, stride=1, padding=0, bias=False)\n","        bn2 = nn.BatchNorm2d(192)\n","        conv3 = nn.Conv2d(192, 192, kernel_size=3, stride=1, padding=0, bias=False)\n","        bn3 = nn.BatchNorm2d(192)\n","        conv4 = nn.Conv2d(192, 2, kernel_size=1, stride=1, padding=0, bias=False)\n","        bn4 = nn.BatchNorm2d(2)\n","        relu = nn.ReLU(inplace=True)\n","        avgpool = nn.AdaptiveAvgPool2d((1, 1))\n","        flatten = nn.Flatten()\n","        linear = nn.Linear(2, 1)\n","        sigmoid = nn.Sigmoid()\n","\n","        self.layers = nn.Sequential(\n","            conv1,\n","            bn1,\n","            relu,\n","            conv2,\n","            bn2,\n","            relu,\n","            conv3,\n","            bn3,\n","            conv4,\n","            bn4,\n","            relu,\n","            avgpool,\n","            flatten,\n","            linear,\n","            sigmoid,\n","        )\n","\n","        self.layers.apply(self.init_param)\n","\n","    def forward(self, x):\n","        for itr, layer in enumerate(self.layers):\n","          x = layer(x)\n","\n","        return x\n","\n","    def init_param(self, param):\n","        if type(param) in [nn.Linear, nn.Conv2d]:\n","            nn.init.kaiming_uniform_(param.weight)"],"execution_count":97,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B4YTvSH8XthX"},"source":["### Train and Test Loops"]},{"cell_type":"code","metadata":{"id":"xixHtjZVR5f_","executionInfo":{"status":"ok","timestamp":1638228987888,"user_tz":300,"elapsed":185,"user":{"displayName":"Ameya Mahabaleshwarkar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWewArOnbcuIhn0zZGYi8CvzAMIgNfJVVvaTwTFg=s64","userId":"00795415078516995824"}}},"source":["def dynamically_train_subnet(\n","    resnet_model,\n","    interm_layer,\n","    subnet_model,\n","    subnet_optimizer,\n","    subnet_criterion,\n","    subnet_scheduler,\n","    benign_train_imgs,\n","    benign_test_imgs,\n","    device,\n","    epochs=100,\n","    batch_size=64,\n","):\n","    subnet_model.train()\n","    resnet_model.eval()\n","\n","    best_loss = float('inf')\n","    for epoch in range(epochs):\n","      \n","      avg_loss = 0.0\n","      for batch_itr in tqdm(range(0, len(benign_train_imgs), batch_size)):\n","\n","        # get resnet outputs of benign imgs and labels as '0'\n","        benign_inputs = benign_train_imgs[batch_itr:batch_itr+batch_size].float().to(device)\n","        benign_inputs = resnet_model(benign_inputs, return_interm_layer=interm_layer)\n","        benign_train_labels = torch.zeros((benign_inputs.shape[0], 1), dtype=torch.float32)\n","\n","        # create a attack instance using current state of the subnet\n","        train_attack = torchattacks.PGD(subnet_model, eps=4/255, alpha=1/255, steps=40)\n","        adv_inputs = train_attack(benign_inputs, benign_train_labels)\n","        adv_train_labels = torch.ones((adv_inputs.shape[0], 1), dtype=torch.float32)\n","\n","        # create a 2x batch with adv and benign images\n","        input = torch.cat((benign_inputs, adv_inputs), axis=0)\n","        labels = torch.cat((benign_train_labels, adv_train_labels), axis=0)\n","\n","        # shuffle the combined inputs and labels\n","        assert input.shape[0] == labels.shape[0]\n","        shuffle_indices = np.arange(input.shape[0])\n","        np.random.shuffle(shuffle_indices)\n","        input, labels = input[shuffle_indices].squeeze(0), labels[shuffle_indices].squeeze(0)\n","\n","        # feed to subnet\n","        input, labels = input.to(device), labels.to(device)\n","        output = subnet_model(input)\n","\n","        # calculate loss\n","        loss = subnet_criterion(output, labels)\n","        loss.backward()\n","        avg_loss += loss.item()\n","\n","        # param update\n","        subnet_optimizer.step()\n","\n","        # cleanup\n","        del input\n","        del labels\n","        del loss\n","        torch.cuda.empty_cache()\n","\n","      avg_loss /= len(benign_train_imgs) // 64\n","\n","      val_loss, val_acc, val_roc = dynamically_test_subnet(\n","          resnet_model,\n","          interm_layer,\n","          subnet_model,\n","          subnet_criterion,\n","          benign_test_imgs,\n","          device,\n","      )\n","\n","      print('Train Loss: {:.4f} | Val Loss: {:.4f} | Val Accuracy: {:.4f} | Val ROC: {:.4f}'.format(avg_loss, val_loss, val_acc, val_roc))\n","      break\n","      if val_loss > best_loss:\n","        best_loss = val_loss\n","        torch.save({\n","            'epoch': epoch,\n","            'model_state_dict': subnet_model.state_dict(),\n","            'optimizer_state_dict': subnet_optimizer.state_dict(),\n","        }, './' + str(epoch) + 'model.pt')\n","\n","      subnet_scheduler.step(val_loss)"],"execution_count":98,"outputs":[]},{"cell_type":"code","metadata":{"id":"kbAPinH0T_fB","executionInfo":{"status":"ok","timestamp":1638228988078,"user_tz":300,"elapsed":3,"user":{"displayName":"Ameya Mahabaleshwarkar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWewArOnbcuIhn0zZGYi8CvzAMIgNfJVVvaTwTFg=s64","userId":"00795415078516995824"}}},"source":["def dynamically_test_subnet(\n","    resnet_model,\n","    interm_layer,\n","    subnet_model,\n","    subnet_criterion,\n","    benign_test_imgs,\n","    device,\n","    batch_size=64,\n","    threshold=0.5,\n","):\n","    resnet_model.eval()\n","    subnet_model.eval()\n","    test_loss = []\n","    accuracies = []\n","    roc_scores = []\n","\n","    for batch_itr in tqdm(range(0, len(benign_test_imgs), batch_size)):\n","\n","        # get resnet outputs of benign imgs and labels as '0'\n","        benign_inputs = benign_test_imgs[batch_itr:batch_itr+batch_size].float().to(device)\n","        benign_inputs = resnet_model(benign_inputs, return_interm_layer=interm_layer)\n","        benign_test_labels = torch.zeros((benign_inputs.shape[0], 1), dtype=torch.float32)\n","        \n","        # create a attack instance using current state of the subnet\n","        val_attack = torchattacks.PGD(subnet_model, eps=2/255, alpha=1/255, steps=40)\n","        adv_inputs = val_attack(benign_inputs, benign_test_labels)\n","        adv_test_labels = torch.ones((adv_inputs.shape[0], 1), dtype=torch.float32)\n","\n","        # create a 2x batch with adv and benign images\n","        input = torch.cat((benign_inputs, adv_inputs), axis=0)\n","        labels = torch.cat((benign_test_labels, adv_test_labels), axis=0)\n","\n","        # shuffle the combined inputs and labels\n","        assert input.shape[0] == labels.shape[0]\n","        shuffle_indices = np.arange(input.shape[0])\n","        np.random.shuffle(shuffle_indices)\n","        input, labels = input[shuffle_indices].squeeze(0), labels[shuffle_indices].squeeze(0)\n","\n","        # feed to subnet\n","        input, labels = input.to(device), labels.to(device)\n","        with torch.no_grad():\n","            output = subnet_model(input)\n","\n","        # get labels based on threshold and calculate loss\n","        pred_labels = (output > threshold).float()\n","        loss = subnet_criterion(output, labels)\n","\n","        print(\"output\", output.flatten().cpu())\n","        print(\"labels\", labels.flatten().cpu())\n","        print(\"1/0 outputs\", pred_labels.flatten().cpu())\n","\n","        # calculate metrics\n","        accuracy = accuracy_score(labels.flatten().cpu(), pred_labels.flatten().cpu())\n","        accuracies.append(accuracy)\n","        roc_score = roc_auc_score(labels.flatten().cpu(), pred_labels.flatten().cpu())\n","        roc_scores.append(roc_score)\n","        test_loss.extend([loss.item()]*input.size()[0])\n","        \n","        # cleanup\n","        del input\n","        del labels\n","        del loss\n","        torch.cuda.empty_cache()\n","\n","    subnet_model.train()\n","\n","    return np.mean(test_loss), np.mean(accuracies), np.mean(roc_scores)"],"execution_count":99,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hu7KDO5DZGgp"},"source":["### Read Benign Data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4VhfAotEYd-j","executionInfo":{"status":"ok","timestamp":1638228988636,"user_tz":300,"elapsed":185,"user":{"displayName":"Ameya Mahabaleshwarkar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWewArOnbcuIhn0zZGYi8CvzAMIgNfJVVvaTwTFg=s64","userId":"00795415078516995824"}},"outputId":"e0e57d49-a2a3-4b2a-d7e0-bc676d9dcc64"},"source":["!ls '/content/drive/MyDrive/11785 - Project/data'"],"execution_count":100,"outputs":[{"output_type":"stream","name":"stdout","text":["benign_cifar.npy\t      fgsm_mnist_eps0.5.npy\n","benign_cifar_train.npy\t      pgd_cifar_default_art.npy\n","benign_mnist.npy\t      pgd_cifar_default_torchattacks_new.npy\n","benign_mnist_train.npy\t      pgd_cifar_eps0.1_torchattacks.npy\n","cwlinf_cifar_default_art.npy  pgd_cifar_eps0.3_alpha0.1_steps7.npy\n","cwlinf_mnist_default_art.npy  pgd_mnist_default_art.npy\n","fgsm_cifar_default_art.npy    pgd_mnist_eps0.3_alpha0.1_steps7.npy\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E43gPXw_Yhps","executionInfo":{"status":"ok","timestamp":1638228989814,"user_tz":300,"elapsed":1180,"user":{"displayName":"Ameya Mahabaleshwarkar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWewArOnbcuIhn0zZGYi8CvzAMIgNfJVVvaTwTFg=s64","userId":"00795415078516995824"}},"outputId":"5e42803d-4ff7-47e5-b9f0-6e9f3268eafe"},"source":["batch_size = 64\n","\n","# benign data\n","benign_imgs_path = \"/content/drive/MyDrive/11785 - Project/data/benign_cifar_train.npy\"\n","benign_imgs = np.load(benign_imgs_path, allow_pickle=True).astype(float)\n","benign_imgs = torch.from_numpy(benign_imgs) # .transpose(0, 3, 1, 2))\n","shuffle_indices = np.arange(benign_imgs.shape[0])\n","np.random.shuffle(shuffle_indices)\n","benign_imgs = benign_imgs[shuffle_indices]\n","print(f\"benign data shape: {benign_imgs.shape}\")\n","\n","# train-test split\n","benign_train_imgs = benign_imgs[:45000]\n","benign_test_imgs = benign_imgs[45000:]"],"execution_count":101,"outputs":[{"output_type":"stream","name":"stdout","text":["benign data shape: torch.Size([50000, 3, 32, 32])\n"]}]},{"cell_type":"markdown","metadata":{"id":"KNrIUMbmZNtg"},"source":["### Load Base Model - ResNet"]},{"cell_type":"code","metadata":{"id":"422VZVAaZKp_"},"source":["! ls \"/content/drive/MyDrive/11785 - Project/\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wjRMc5TtZRLu"},"source":["cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if cuda else \"cpu\")\n","\n","resnet_model = resnet32()\n","resnet_model.to(device)\n","checkpoint = torch.load(\"/content/drive/MyDrive/11785 - Project/cifar10_model.pth\")\n","resnet_model.load_state_dict(checkpoint)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"J0uU_mt2Za4C"},"source":["### Create SubNet"]},{"cell_type":"code","metadata":{"id":"8ljAeRdgZc-s","executionInfo":{"status":"ok","timestamp":1638228990650,"user_tz":300,"elapsed":4,"user":{"displayName":"Ameya Mahabaleshwarkar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWewArOnbcuIhn0zZGYi8CvzAMIgNfJVVvaTwTFg=s64","userId":"00795415078516995824"}}},"source":["# output size at diff intermediate layers of resnet\n","interm_layer2dim = {1: 16, 2: 32, 3: 64}\n","interm_layer = 3\n","\n","subnet_model = SubNet(interm_layer2dim[interm_layer])\n","subnet_model.to(device)\n","subnet_optimizer = torch.optim.Adam(subnet_model.parameters(), lr=0.0001, betas=(0.99, 0.999))\n","subnet_criterion = nn.BCELoss()\n","subnet_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(subnet_optimizer, 'min', factor=0.75, patience=1)"],"execution_count":104,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GAaJqpImZwek"},"source":["### Run Training"]},{"cell_type":"code","metadata":{"id":"0g8hEdD-Zx9N"},"source":["dynamically_train_subnet(\n","  resnet_model,\n","  interm_layer,\n","  subnet_model,\n","  subnet_optimizer,\n","  subnet_criterion,\n","  subnet_scheduler,\n","  benign_train_imgs,\n","  benign_test_imgs,\n","  device,\n","  epochs=50,\n","  batch_size=64,\n",")"],"execution_count":null,"outputs":[]}]}